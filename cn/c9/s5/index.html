
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="计算机图形学概论(graphicsbook)">
      
      
      
        <link rel="canonical" href="https://hellowac.github.io/graphicsbook-zh-cn/cn/c9/s5/">
      
      
        <link rel="prev" href="../s4/">
      
      
        <link rel="next" href="../s6/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.28">
    
    
      
        <title>9.5 纹理 - 计算机图形学概论</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 12a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M6 13h8l-3.5 3.5 1.42 1.42L17.84 12l-5.92-5.92L10.5 7.5 14 11H6v2Z"/></svg>');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="default" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#95-纹理" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="计算机图形学概论" class="md-header__button md-logo" aria-label="计算机图形学概论" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            计算机图形学概论
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              9.5 纹理
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="选择当前语言">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/graphicsbook-zh-cn/en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/graphicsbook-zh-cn/cn/" hreflang="cn" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/hellowac/graphicsbook-zh-cn" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    graphicsbook
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../" class="md-tabs__link">
        
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../preface/" class="md-tabs__link">
        
  
    
  
  前言

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c1/" class="md-tabs__link">
          
  
    
  
  1.简介

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c2/" class="md-tabs__link">
          
  
    
  
  2.二维图形

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c3/" class="md-tabs__link">
          
  
    
  
  3.几何

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c4/" class="md-tabs__link">
          
  
    
  
  4.灯光和材质

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c5/" class="md-tabs__link">
          
  
    
  
  5.three.js

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c6/" class="md-tabs__link">
          
  
    
  
  6.WebGL

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c7/" class="md-tabs__link">
          
  
    
  
  7.WebGL 3D

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c8/" class="md-tabs__link">
          
  
    
  
  8.高阶3D

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  9.WEBGPU

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a1/" class="md-tabs__link">
          
  
    
  
  附录A

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a2/" class="md-tabs__link">
          
  
    
  
  附录B

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a3/" class="md-tabs__link">
          
  
    
  
  附录C

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../source/" class="md-tabs__link">
          
  
    
  
  附录D

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../glossary/" class="md-tabs__link">
          
  
    
  
  术语表

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  关于

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="计算机图形学概论" class="md-nav__button md-logo" aria-label="计算机图形学概论" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    计算机图形学概论
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/hellowac/graphicsbook-zh-cn" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    graphicsbook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preface/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    1.简介
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            1.简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 1 节 绘画与绘图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 2 节：三维(3D)图形的要素
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 3 节：硬件与软件
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    2.二维图形
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            2.二维图形
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第1节: 像素、坐标和颜色
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第2节: 形状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第3节: 变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第4节: 分层建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第5节: Java 绘制2D
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第6节: HTML Canvas图形
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第7节: SVG：一种场景描述语言
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    3.几何
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            3.几何
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 OpenGL 1.1 中的形状和颜色
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 3D 坐标和变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 投影与观看
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 多边形网格和 glDrawArrays
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.5 部分线性代数基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.6 使用 GLUT 和 JOGL
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c4/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    4.灯光和材质
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            4.灯光和材质
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 照明简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 OpenGL 1.1 中的光和材质
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 图像纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 灯光、相机、动作
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c5/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    5.three.js
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            5.three.js
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 Three.js 基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 构建对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 其他功能
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c6/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    6.WebGL
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_8" id="__nav_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            6.WebGL
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 可编程流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 第一个例子
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 GLSL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 图像纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 实现 2D 变换
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c7/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    7.WebGL 3D
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_9" id="__nav_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            7.WebGL 3D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c7/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 3D变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c7/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.2 照明和材质
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c7/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.3 纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c7/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.4 帧缓冲区
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c7/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.5 WebGL 扩展
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c8/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    8.高阶3D
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_10" id="__nav_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            8.高阶3D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c8/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.1 光线追踪
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c8/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.2 路径追踪
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    9.WEBGPU
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            9.WEBGPU
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.1 WebGPU 基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.2 实例和索引
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.3 WGSL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.4 WebGPU 中的 3D 图形
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    9.5 纹理
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    9.5 纹理
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#951-纹理坐标" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.1 纹理坐标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#952-纹理和采样器" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.2 纹理和采样器
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#953-mipmap" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.3 Mipmap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#954-立方体贴图纹理" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.4 立方体贴图纹理
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#955-纹理格式" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.5 纹理格式
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.6 计算着色器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.7 细节
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录A
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_12" id="__nav_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            附录A
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.1 Java 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.2 C 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.3 JavaScript 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.4 JavaScript Promise 和异步函数
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录B
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_13" id="__nav_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            附录B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.1 节 Blender 基础知识
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.2 节 Blender 建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.3 节 Blender 动画
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.4 节 有关光和材料的更多信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录C
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14" id="__nav_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            附录C
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a3/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C.1 节 Gimp：2D 绘画程序
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../source/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录D
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            附录D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_16" >
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    术语表
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            术语表
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    术语表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#951-纹理坐标" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.1 纹理坐标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#952-纹理和采样器" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.2 纹理和采样器
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#953-mipmap" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.3 Mipmap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#954-立方体贴图纹理" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.4 立方体贴图纹理
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#955-纹理格式" class="md-nav__link">
    <span class="md-ellipsis">
      9.5.5 纹理格式
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="95-纹理">9.5 <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr><a class="headerlink" href="#95-纹理" title="Permanent link">&para;</a></h1>
<p><strong>Textures</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">中文</label><label for="__tabbed_1_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>纹理本质上是图元上从一点到另一点变化的某些属性。最常见的 —— 或者至少是最可见的 —— 一种纹理是颜色从点到点的变化，最常见的颜色纹理是图像纹理。其他类型的纹理，如反射率或法向量的变化，也是可能的。</p>
<p>图像纹理在 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 中的 <a href="../../c4/s3/">第4.3节</a> 以及 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中的 <a href="../../c6/s4/">第6.4节</a> 和 <a href="../../c7/s3/">第7.3节</a> 有介绍。大多数基本思想都适用于 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr>，尽管编码细节不同。</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 拥有一维、二维和三维图像纹理以及立方体贴图纹理（见 <a href="../../c5/s3/#534-立方体贴图纹理和天空盒">5.3.4小节</a>）。在本节的大部分内容中，我将集中讨论二维图像纹理。</p>
</div>
<div class="tabbed-block">
<p>A <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is simply some property that varies from point to point on a primitive. The most common—or at least the most visible—kind of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is a variation in color from point to point, and the most common type of color <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>. Other kinds of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, such as variations in <abbr title="The proportion or fraction of incident light that is reflected by an object. An object can have different reflectivities at different wavelengths. The color of an object is determined by its reflectivities at all wavelengths.">reflectivity</abbr> or <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>, are also possible.</p>
<p>Image textures were covered in <a href="../../c4/s3/">Section 4.3</a> for <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> and in <a href="../../c6/s4/">Section 6.4</a> and <a href="../../c7/s3/">Section 7.3</a> for <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>. Most of the basic ideas carry over to <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr>, even though the coding details are different.</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> has one-, two-, and three-dimensional image textures plus cubemap textures (<a href="../../c5/s3/#534-立方体贴图纹理和天空盒">Subsection 5.3.4</a>). I will concentrate on two-dimensional image textures for most of this section.</p>
</div>
</div>
</div>
<h2 id="951-纹理坐标">9.5.1 <abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr><a class="headerlink" href="#951-纹理坐标" title="Permanent link">&para;</a></h2>
<p><strong>Texture Coordinates</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">中文</label><label for="__tabbed_2_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>当图像纹理应用于表面时，通过基于该点的纹理坐标对纹理进行<strong><abbr title="将纹理坐标映射到纹理中的颜色的操作，包括如果可用则使用 mipmap，并在必要时应用缩小或放大滤波器。">采样</abbr></strong>，以获取该点的纹理颜色。采样是在 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 程序的 <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> 端使用类型为 sampler 的 <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> 变量完成的。</p>
<p>2D 图像纹理带有标准的 (u,v) <abbr title="一种将数值坐标分配给几何点的方法。在二维中，每个点对应一对数字。在三维中，每个点对应一组三个数字。">坐标系</abbr>。坐标在图像上的范围是 0 到 1。纹理坐标在 0 到 1 范围之外的行为取决于用于采样纹理的采样器。对于 1D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，只使用 u <abbr title="一种将数值坐标分配给几何点的方法。在二维中，每个点对应一对数字。在三维中，每个点对应一组三个数字。">坐标</abbr>，对于 3D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，坐标系被称为 (u,v,w)。</p>
<p>在将 2D 纹理图像应用于表面时，表面上某点的两个纹理坐标将该表面点映射到 (u,v) 坐标系中的点。采样过程使用 (u,v) 坐标从图像中查找颜色。查找过程可能很复杂，被称为“过滤”，可能涉及查看图像及其 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 中的多个 texels 的颜色（记住，纹理中的像素通常被称为 texels）。</p>
<p>按照惯例，我们可以将纹理坐标 (0,0) 指向图像的左上角，u 从右向左增加，v 从上到下增加。这只是一种惯例，但它对应于网络上图像数据的存储方式：图像左上角像素的数据首先被存储，数据按行存储，从图像顶部到底部。</p>
<p>注意，<abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 中的纹理坐标系统使用 r, s 和 t 作为坐标名称，而不是 u, v 和 w。<abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 中的约定是 t 轴指向上方，<abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr> (0,0) 指向图像的左下角。考虑到这一点，请参见 <a href="../../c4/s3/#431-纹理坐标">4.3.1小节</a> 以更深入地讨论纹理坐标及其使用方法。</p>
<p>示例程序 <a href="../../../en/source/webgpu/first_texture.html">webgpu/first_texture.html</a> 是我们在 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 中使用纹理的第一个示例。这个简单程序只是在一个正方形上绘制了三种不同的纹理：</p>
<p><a class="glightbox" href="../../../en/c9/webgpu-textures.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c9/webgpu-textures.png" /></a></p>
<p>正方形的纹理坐标从左上角的 (0,0) 到右下角的 (1,1)。在图片中左边的正方形上，某点的纹理坐标被用作该点颜色的红色和绿色分量。（没有纹理图像。这是一个过程纹理的微不足道的例子（见 <a href="../../c7/s3/#733-程序纹理">7.3.3小节</a>）。右边的正方形使用图像纹理，其中“蒙娜丽莎”图像来自文件。中间的正方形也使用图像纹理，但在这个案例中，图像的颜色来自程序的一部分的像素颜色数组。该图像是一个非常小的四像素图像，有两行像素和两列像素。原始的纹理坐标在正方形上在采样纹理之前被乘以 5，以便我们在正方形上看到 5 份纹理的副本。（这是一个纹理变换的非常简单的例子（见 <a href="../../c4/s3/#434-纹理变换">4.3.4小节</a>)。</p>
<p>尽管我们将在本节的大部分时间讨论这个基本示例，您也可以查看 <a href="../../../en/source/webgpu/textured_objects.html">webgpu/textured_objects.html</a>，它将纹理应用于三维形状，以及 <a href="../../../en/source/webgpu/texture_from_canvas.html">webgpu/texture_from_canvas.html</a>，它从同一页面上的画布获取纹理的图像。</p>
<p>采样是在片段着色器中完成的。用于采样的纹理坐标可能来自任何地方。但大多数情况下，纹理坐标作为顶点属性输入到着色器程序。然后，插值的纹理坐标被传递到片段着色器，在那里它们被用来采样纹理。</p>
<p>在示例程序中，正方形被绘制为具有四个顶点的三角形条带。有两个顶点属性，分别给出每个顶点的坐标和纹理坐标。这两个属性交错存储在一个单独的顶点缓冲区中（见 <a href="../s1/#916-多个顶点输入">9.1.6小节</a>）。数据来自这个数组：</p>
<div class="highlight"><pre><span></span><code><span class="kd">const</span><span class="w"> </span><span class="nx">vertexData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ow">new</span><span class="w"> </span><span class="nb">Float32Array</span><span class="p">([</span>
<span class="w">    </span><span class="cm">/* 坐标 */</span><span class="w">     </span><span class="cm">/* 纹理坐标 */</span>
<span class="w">    </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w">      </span><span class="c1">// 左下角的数据</span>
<span class="w">    </span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w">      </span><span class="c1">// 右下角的数据</span>
<span class="w">    </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">  </span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w">      </span><span class="c1">// 左上角的数据</span>
<span class="w">    </span><span class="mf">0.8</span><span class="p">,</span><span class="w">  </span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w">      </span><span class="c1">// 右上角的数据</span>
<span class="p">]);</span>
</code></pre></div>
<p>请注意，左上角的纹理坐标是 (0,0)，右下角是 (1,1)。您应该检查这与插图中第一个正方形上的颜色如何对应。当用于将图像纹理映射到正方形上（没有纹理变换）时，正方形将显示图像的一个完整副本，以通常的方向显示。如果 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 纹理坐标的约定用于正方形上，<abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr> (0,0) 将被分配给正方形的左下角，图像将出现倒置。为了解决这个问题，在将图像数据加载到纹理之前，<abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 中的图像通常会垂直翻转。见 <a href="../../c6/s4/#642-处理图像">6.4.2小节</a> 的末尾。如果您使用的是带有纹理坐标的几何模型，它们很可能是为 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 设计的纹理坐标，您可能会发现您需要翻转您的图像以正确地应用到模型上。例如，在 <a href="../../../en/source/webgpu/textured_objects.html">textured objects</a> 示例中就是这种情况。</p>
</div>
<div class="tabbed-block">
<p>When an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr> is applied to a surface, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> color for a point is obtained by <strong><abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr></strong> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, based on <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for that point. Sampling is done on the <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> side of a <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> program, using a <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> variable of type sampler.</p>
<p>A 2D <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr> comes with a standard (u,v) <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr>. The coordinates range from 0 to 1 on the image. What happens for <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates outside the range 0 to 1 depends on the sampler that is used to sample the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. For a 1D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, only the u coordinate is used, and for a 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> is referred to as (u,v,w).</p>
<p>When applying a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image to a surface, the two <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for a point on the surface map that surface point to a point in the (u,v) <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr>. The <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> process uses the (u,v) coordinates to look up a color from the image. The look-up process can be nontrivial. It is referred to as "filtering" and can involve looking at the colors of multiple texels in the image and its <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>. (Remember that <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr> in a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> are often referred to as texels.)</p>
<p>By convention, we can take <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates (0,0) to refer to the top-left corner of the image, with u increasing from right to left and v increasing from top to bottom. This is really just a convention, but it corresponds to the way that data for images on the web is usually stored: The data for the top-left <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> is stored first, and the data is stored row-by-row, from the top of the image to the bottom.</p>
<p>Note that the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> in <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> uses r, s, and t as the coordinate names instead of u, v, and w. The convention in <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> is that the t-axis points upward, with <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates (0,0) referring to the bottom-left corner of the image. With that in mind, see <a href="../../c4/s3/#431-纹理坐标">Subsection 4.3.1</a> for a more in-depth discussion of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates and how they are used.</p>
<p>The sample program <a href="../../../en/source/webgpu/first_texture.html">webgpu/first_texture.html</a> is our first example of using textures in <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr>. This simple program just draws a square with three different textures:</p>
<p><a class="glightbox" href="../../../en/c9/webgpu-textures.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c9/webgpu-textures.png" /></a></p>
<p>Texture coordinates for the square range from (0,0) at the top left corner of the square to (1,1) at the bottom right corner. For the square on the left in the picture, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for a point on the square are used as the red and green components of the color for that point. (There is no <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image. This is a trivial example of a <abbr title="A texture for which the value at a given set of texture coordinates is computed as a mathematical function of the coordinates, as opposed to an image texture where the value is obtained by sampling an image.">procedural texture</abbr> (<a href="../../c7/s3/#733-程序纹理">Subsection 7.3.3</a>).) The square on the right uses an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>, where the "Mona Lisa" image comes from a file. The middle square also uses an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>, but in this case the colors for the image come from an array of <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> colors that is part of the program. The image is a tiny four-<abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> image, with two rows of <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr> and two columns. The original <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates on the square are multiplied by 5 before <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, so that we see 5 copies of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> across and down the square. (This is a very simple example of a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation (<a href="../../c4/s3/#434-纹理变换">Subsection 4.3.4</a>).)</p>
<p>Although we will spend much of this section on this basic example, you can also look at <a href="../../../en/source/webgpu/textured_objects.html">webgpu/textured_objects.html</a>, which applies textures to three-dimensional shapes, and <a href="../../../en/source/webgpu/texture_from_canvas.html">webgpu/texture_from_canvas.html</a>, which takes the image for a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> from a canvas on the same page.</p>
<hr />
<p>Sampling is done in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>. The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates that are used for <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> could come from anywhere. But most often, <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are input to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program as a <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr>. Then, interpolated <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are passed to the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>, where they are used to sample the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.</p>
<p>In the sample program, the square is drawn as a triangle-strip with four vertices. There are two <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attributes</abbr>, giving the coordinates and the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for each <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr>. The two <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attributes</abbr> are stored interleaved in a single <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> buffer (see <a href="../s1/#916-多个顶点输入">Subsection 9.1.6</a>). The data comes from this array:</p>
<div class="highlight"><pre><span></span><code><span class="kd">const</span><span class="w"> </span><span class="nx">vertexData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ow">new</span><span class="w"> </span><span class="nb">Float32Array</span><span class="p">([</span>
<span class="cm">/* coords */</span><span class="w">     </span><span class="cm">/* texcoords */</span>
<span class="w">    </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w">      </span><span class="c1">// data for bottom left corner</span>
<span class="w">    </span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w">      </span><span class="c1">// data for bottom right corner</span>
<span class="w">    </span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span><span class="w">  </span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w">      </span><span class="c1">// data for top left corner</span>
<span class="w">    </span><span class="mf">0.8</span><span class="p">,</span><span class="w">  </span><span class="mf">0.8</span><span class="p">,</span><span class="w">       </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w">      </span><span class="c1">// data for top right corner</span>
<span class="p">]);</span>
</code></pre></div>
<p>Note that the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for the top left corner are (0,0) and for the bottom right corner are (1,1). You should check out how this corresponds to the colors on the first square in the illustration. When used to map an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr> onto the square (with no <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation), the square will show one full copy of the image, in its usual orientation. If the <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> convention for <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates were used on the square, <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates (0,0) would be assigned to the bottom left corner of the square, and the image would appear upside-down. To account for this, images in <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> are often flipped vertically before loading the image data into a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. See the end of <a href="../../c6/s4/#642-处理图像">Subsection 6.4.2</a>. If you use geometric models that come with <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, they might well be <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates designed for <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr>, and you might find that you need to flip your images to get them to apply correctly to the model. This is true, for example, in the <a href="../../../en/source/webgpu/textured_objects.html">textured objects</a> example.</p>
</div>
</div>
</div>
<h2 id="952-纹理和采样器">9.5.2 纹理和采样器<a class="headerlink" href="#952-纹理和采样器" title="Permanent link">&para;</a></h2>
<p><strong>Textures and Samplers</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">中文</label><label for="__tabbed_3_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>在 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 程序中，纹理和采样器在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端创建，并在 <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> 端使用，它们在片段着色器中作为着色器资源。这意味着它们被声明为着色器程序中的全局变量。它们的值通过绑定组传递给着色器，因此采样器或纹理变量必须使用 @group 和 @binding 注解进行声明。例如，声明一个表示 2D 图像纹理资源的变量 tex 可能如下所示：</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="n">binding</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">var</span><span class="w"> </span><span class="n">tex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">texture_2d</span><span class="o">&lt;</span><span class="n">f32</span><span class="o">&gt;</span><span class="p">;</span>
</code></pre></div>
<p>类型名 <code>texture_2d&lt;f32&gt;</code> 指的是一个 2D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，其样本类型为 f32；也就是说，通过采样纹理返回的颜色将是 vec4f 类型。一个带有浮点样本的 1D 纹理将使用类型名 <code>texture_1d&lt;f32&gt;</code>，对于 3D 和立方体贴图也有类似的名称。（还有像 <code>texture_2d&lt;u32&gt;</code> 和 <code>texture_1d&lt;i32&gt;</code> 这样的整型纹理，但它们不与采样器一起使用。本节后面会讨论它们。）</p>
<p>注意，纹理变量是使用不带地址空间的 var 声明的。（与 uniform 地址空间中的变量使用 <code>var&lt;uniform&gt;</code> 不同。）采样器变量也是如此。纹理和采样器被认为处于特殊的“句柄”地址空间，但这个名称在着色器程序中不使用。</p>
<p>采样器变量使用类型名 sampler 声明。（不幸的是，这意味着您不能将“sampler”作为变量名。）例如：</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="n">binding</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="n">var</span><span class="w"> </span><span class="n">samp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">sampler</span><span class="p">;</span>
</code></pre></div>
<p>采样器是一个简单的数据结构，它指定了采样过程的某些方面，例如缩小滤波器以及是否使用各向异性过滤。</p>
<p>纹理和采样器的值在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端构建。着色器程序无法直接访问纹理或采样器的内部结构。实际上，在 <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> 中，您可以使用它们的唯一操作就是将它们作为参数传递给函数。有几个内置函数用于处理纹理（它们中的大多数太晦涩，这里不涉及）。主要的采样纹理函数是 textureSample()。它的参数是一个浮点纹理、一个采样器和纹理坐标。例如，</p>
<div class="highlight"><pre><span></span><code><span class="n">let</span><span class="w"> </span><span class="n">textureColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">textureSample</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">tex</span><span class="p">,</span><span class="w"> </span><span class="n">samp</span><span class="p">,</span><span class="w"> </span><span class="n">texcoords</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>这个函数可以用于采样 1D、2D、3D 和立方体贴图。对于 1D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，texcoords 参数是一个 f32；对于 2D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，它是一个 vec2f；对于 3D 或立方体贴图，它是一个 vec3f。返回值是一个表示 RGBA 颜色的 vec4f。即使纹理实际上没有存储四个颜色分量，返回值也总是 vec4f。例如，一个纹理可能只存储一个颜色分量；当它使用 textureSample() 进行采样时，纹理中的颜色值将用作颜色的红色分量，绿色和蓝色分量将被设置为 0.0，<abbr title="An extra component (that is, one of the numbers that are used to specify a color) in a color model that is not part of the actual color specification. The alpha component is extra information. It is most often used to specify the degree of transparency of a color.">alpha</abbr> 分量将为 1.0。</p>
<p>现在您应该能够理解示例程序中的片段着色器源代码。大部分工作在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端，所以着色器代码相当简单：</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">sampler</span><span class="p">;</span><span class="w">  </span><span class="c1">// 来自 JavaScript 的采样器资源。</span>
<span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">tex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">texture_2d</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span><span class="w">  </span><span class="c1">// 图像纹理资源。</span>

<span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">textureSelect</span><span class="o">:</span><span class="w"> </span><span class="nx">u32</span><span class="p">;</span>
<span class="c1">// 值为 1、2 或 3，告诉片段着色器使用哪个纹理。</span>

<span class="err">@</span><span class="nx">fragment</span>
<span class="nx">fn</span><span class="w"> </span><span class="nx">fragmentMain</span><span class="p">(</span><span class="err">@</span><span class="nx">location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">vec2f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="err">@</span><span class="nx">location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">textureSelect</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// 简单的程序纹理。</span>
<span class="w">        </span><span class="c1">// 将 texcoords 作为红/绿颜色分量。</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">vec4f</span><span class="p">(</span><span class="w"> </span><span class="nx">texcoords</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">textureSelect</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// 对于棋盘格纹理。</span>
<span class="w">        </span><span class="c1">// 应用纹理变换：将 texcoords 乘以 5。</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="mf">5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// 对于蒙娜丽莎纹理；没有纹理变换。</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>由于选项有限，纹理和采样器在着色器程序中的使用相当简单。大部分工作在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端。</p>
<hr />
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 中采样器的目的是为采样过程设置选项。采样器是使用 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 函数 device.createSampler() 创建的。以下代码创建了一个典型的高质量 2D 纹理采样的采样器：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">sampler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createSampler</span><span class="p">({</span>
<span class="w">    </span><span class="nx">addressModeU</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;repeat&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// 默认是 &quot;clamp-to-edge&quot;。</span>
<span class="w">    </span><span class="nx">addressModeV</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;repeat&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">//    （另一个可能的值是 &quot;mirror-repeat&quot;。）</span>
<span class="w">    </span><span class="nx">minFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="nx">magFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span><span class="w">     </span><span class="c1">// 过滤器的默认值是 &quot;nearest&quot;。</span>
<span class="w">    </span><span class="nx">mipmapFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nx">maxAnisotropy</span><span class="o">:</span><span class="w"> </span><span class="mf">16</span><span class="w">        </span><span class="c1">// 默认值是 1；16 是最大值。</span>
<span class="p">});</span>
</code></pre></div>
<p>addressModeU 属性指定如何处理超出 0 到 1 范围的 u 纹理坐标的值，addressModeV 对 v 坐标做同样的事情，对于 3D 纹理还有 addressModeW。（在 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 和 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中，这被称为“包裹”；见 <a href="../../c4/s3/#433-纹理目标和纹理参数">4.3.3小节</a>。这里的含义是相同的。）</p>
<p>过滤考虑到图像在应用到表面时通常需要被拉伸或缩小。magFilter 或放大滤波器用于拉伸图像时。minFilter 或缩小滤波器用于缩小它时。<abbr title="一系列逐渐缩小尺寸的纹理图像副本，宽度和高度逐渐减小。从原始图像开始，每个mipmap通过将前一个图像的宽度和高度除以二（除非已经是1）来获得。最后的mipmap是一个单一像素。Mipmaps用于更有效地将纹理图像映射到表面上，当图像必须缩小以适应表面时。">Mipmaps</abbr> 是图像的缩小尺寸副本，可以使过滤更有效。纹理不会自动带有 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>；如果没有 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>，mipmapFilter 将被忽略。这与 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 相似；见 <a href="../../c4/s3/#432-mipmap-和过滤">4.3.2小节</a>。</p>
<p>maxAnisotropy 属性控制各向异性过滤，这在 <a href="../../c7/s5/#751-各向异性过滤">7.5.1小节</a> 中解释。默认值 1 表示不使用各向异性过滤。更高的值可以为边缘观看的纹理提供更好的质量。最大值取决于设备，但指定一个大于最大值的值是可以的；在这种情况下，将使用最大值。</p>
<hr />
<p>纹理是在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端使用 <code>device.createTexture()</code> 创建的。但重要的是要理解，这个函数只分配了 <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> 上将保存纹理数据的内存。实际数据将需要稍后存储。这类似于创建 <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> 缓冲区。以下是示例程序中棋盘纹理的创建方式：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="w">    </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">],</span><span class="w">  </span><span class="c1">// 宽两像素，高两像素。</span>
<span class="w">    </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;rgba8unorm&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// 每个颜色分量一个 8 位无符号整数。</span>
<span class="w">    </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span>
<span class="p">});</span>
</code></pre></div>
<p>这是一个 2D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，默认类型。size 属性指定了纹理的宽度和高度，可以是数组或对象，例如 {width: 2, height: 2}。这里指定的纹理格式 "rgba8unorm" 是图像的常见格式：每个像素有四个 RGBA <abbr title="颜色模型中用于指定颜色的数字之一。例如，在 RGB 颜色模型中，一个颜色由三个颜色分量表示，分别代表颜色中红色、绿色和蓝色的量。">颜色分量</abbr>，每个颜色分量有 8 位。名称中的 "unorm" 意味着 8 位表示范围在 0 到 255 的无符号整数，这些整数被缩放到 0.0 到 1.0 的范围以给出浮点颜色值。（这种缩放被称为 "归一化" 值——这是过度使用的术语 "normal" 的另一种含义。）在 usage 属性中，TEXTURE_BINDING 表示纹理可以在着色器程序中采样，COPY_DST 表示数据可以从其他地方复制到纹理中。也可以通过将纹理附加到管线作为渲染目标来填充纹理的数据；这需要使用 GPUTextureUsage.RENDER_ATTACHMENT。另一种可能的用途是 COPY_SRC，它允许将纹理用作复制数据的源。</p>
<p>size、format 和 usage 属性是必需的。还有一些可选属性。mipLevelCount 属性指定你将为纹理提供的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 数量。默认值 1 表示只提供主图像。dimension 属性可以是 "1d"、"2d" 或 "3d"，默认值为 "2d"。sampleCount 属性的默认值为 1，可以设置为 4 来创建多重采样纹理。</p>
<p>我们已经使用 device.createTexture() 创建了用于多重采样和深度测试的特殊用途纹理。参见，例如，<a href="../../../en/source/webgpu/depth_test.html">webgpu/depth_test.html</a>。这些纹理被用作渲染附件，纹理的数据是通过绘制图像创建的。</p>
<p>图像纹理的数据通常来自程序的 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端。当数据来自 <strong><em>ArrayBuffer</em></strong> 或类型化数组时，可以使用 device.queue.writeTexture() 函数将数据复制到纹理中。在示例程序中，微小棋盘纹理的数据来自一个 <strong><em>Uint8Array</em></strong>，并使用以下方式复制到纹理中：</p>
<div class="highlight"><pre><span></span><code><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">writeTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="c1">// 要写入数据的纹理。</span>
<span class="w">    </span><span class="nx">textureData</span><span class="p">,</span><span class="w">         </span><span class="c1">// 包含要写入数据的 Uint8Array。</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">bytesPerRow</span><span class="o">:</span><span class="w"> </span><span class="mf">8</span><span class="w"> </span><span class="p">},</span><span class="w">  </span><span class="c1">// 每个 texels 行的字节数。</span>
<span class="w">    </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">]</span><span class="w">   </span><span class="c1">// 纹理的大小（宽度和高度）。</span>
<span class="p">);</span>
</code></pre></div>
<p>writeTexture() 的第一个参数是一个对象。除了 <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> 属性外，该对象还可以有一个 mipLevel 属性以将数据复制到纹理的某个 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 中，以及一个 origin 属性以将数据复制到纹理内的矩形子区域中。（origin 可以作为整数数组给出；与函数的大小参数一起，它决定了矩形区域。）第三个参数也是一个对象。bytesPerRow 属性是一行 texels 从一行的开始到下一行的开始之间的字节距离。行之间可能有填充，这有时是满足对齐要求所必需的。还可以有一个 offset <abbr title="图形对象的属性，例如颜色。图像可以通过其包含的几何形状以及它们的属性来指定。">属性</abbr>，给出数据源中数据的起始点，以字节为单位。</p>
<p>所有这些可能看起来过于复杂，但纹理和图像是复杂的，与它们一起工作的函数可以有很多选项。</p>
<hr />
<p>通常，纹理的数据源是图像文件。<abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 不能直接从图像文件中获取数据；您必须获取文件并将数据提取到一个 <strong><em>ImageBitmap</em></strong> 对象中。使用承诺的 fetch <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr> 在 <a href="../../a1/s4/">第 A.4 节</a> 中讨论。这里，例如，是 <a href="../../../en/source/webgpu/textured_objects.html">textured_objects.html</a> 中用于从图像文件加载纹理的函数：</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span><span class="w"> </span><span class="kd">function</span><span class="w"> </span><span class="nx">loadTexture</span><span class="p">(</span><span class="nx">URL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 使用 fetch API 从 URL 获取纹理的标准方法。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">fetch</span><span class="p">(</span><span class="nx">URL</span><span class="p">);</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">blob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">response</span><span class="p">.</span><span class="nx">blob</span><span class="p">();</span><span class="w">  </span><span class="c1">// 将图像数据作为 &quot;blob&quot; 获取。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">createImageBitmap</span><span class="p">(</span><span class="nx">blob</span><span class="p">);</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="w">        </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">],</span>
<span class="w">        </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">                </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">copyExternalImageToTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">source</span><span class="o">:</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">,</span><span class="w"> </span><span class="nx">flipY</span><span class="o">:</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">]</span>
<span class="w">    </span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>纹理的 usage 属性是 copyExternalmageToTexture() 所需的。flipY 属性的使用是因为程序在其显示的对象上使用 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 风格的纹理坐标。source 属性也可以是画布，就像 <a href="../../../en/source/webgpu/texture_from_canvas.html">texture_from_canvas.html</a> 中所做的那样。这个 loadTexture() 函数必须使用 await 从 async 函数中调用，并且捕获可能发生的错误是一个好主意：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span>
<span class="k">try</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">loadTexture</span><span class="p">(</span><span class="nx">URL</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="nx">e</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">...</span>
<span class="p">}</span>
</code></pre></div>
<p>我将不再详细讨论。请参阅示例程序以获取更多示例。</p>
<hr />
<p>在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端创建的采样器和纹理必须作为绑定组资源传递给着色器程序。在绑定组中，采样器的资源是采样器本身，而纹理的资源是纹理的视图。以下是 <a href="../../../en/source/webgpu/first_texture.html">first_texture.html</a> 中棋盘纹理的绑定组示例：</p>
<div class="highlight"><pre><span></span><code><span class="nx">checkerboardBindGroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="w">    </span><span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="nx">bindGroupLayout</span><span class="p">,</span>
<span class="w">    </span><span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span><span class="w">    </span><span class="c1">// 采样器。注意，资源是采样器本身。</span>
<span class="w">            </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span>
<span class="w">            </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardSampler</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span><span class="w">    </span><span class="c1">// 纹理。注意，资源是纹理的视图。</span>
<span class="w">            </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span>
<span class="w">            </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">()</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span><span class="w">    </span><span class="c1">// 资源是包含 uniform 变量的缓冲区。</span>
<span class="w">            </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">2</span><span class="p">,</span>
<span class="w">            </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="nx">buffer</span><span class="o">:</span><span class="w"> </span><span class="nx">uniformBuffer</span><span class="p">,</span><span class="w"> </span><span class="nx">offset</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="mf">4</span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p>Textures and samplers are created on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side of a <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> program and are used on the <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> side, where they are used in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>. This means that they are <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> resources. Like other resources, they are declared as global variables in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program. Their values are passed to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> in bind groups, so a sampler or <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> variable must be declared with @group and @binding annotations. As an example, the declaration of a variable, tex, that represents a 2D <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr> resource could look like this:</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="n">binding</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">var</span><span class="w"> </span><span class="n">tex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">texture_2d</span><span class="o">&lt;</span><span class="n">f32</span><span class="o">&gt;</span><span class="p">;</span>
</code></pre></div>
<p>The type name <code>texture_2d&lt;f32&gt;</code> refers to a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with samples of type f32; that is, the color returned by <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> will be of type vec4f. A 1D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with floating point samples would use type name <code>texture_1d&lt;f32&gt;</code>, and there are similar names for 3D and cube textures. (There are also integer textures with type names like <code>texture_2d&lt;u32&gt;</code> and <code>texture_1d&lt;i32&gt;</code>, but they are not used with samplers. They are discussed later in this section.)</p>
<p>Note that a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> variable is declared using var with no address space. (Not like <code>var&lt;uniform&gt;</code> for variables in the uniform address space.) The same is true for sampler variables. Textures and samplers are considered to be in a special "handle" address space, but that name is not used in <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> programs.</p>
<p>Sampler variables are declared using type name sampler. (Unfortunately, this means that you can't use "sampler" as the name of a variable.) For example:</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="n">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="n">binding</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="n">var</span><span class="w"> </span><span class="n">samp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">sampler</span><span class="p">;</span>
</code></pre></div>
<p>A sampler is a simple data structure that specifies certain aspects of the <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> process, such as the <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr> and whether to use <abbr title="A technique for more accurate sampling of texture images, in the case where a pixel on the surface that is being textured corresponds to a non-rectangular region in the texture. Anisotropic filtering is available as an optional extension in WebGL.">anisotropic filtering</abbr>.</p>
<p>Values for <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> and sampler variables are constructed on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side. A <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program has no direct access to the internal structure of a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> or sampler. In fact, the only thing you can do with them in <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> is pass them as parameters to functions. There are several built-in functions for working with textures (most of them too obscure to be covered here). The main function for <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> textures is textureSample(). Its parameters are a floating-point <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, a sampler, and <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. For example,</p>
<div class="highlight"><pre><span></span><code><span class="n">let</span><span class="w"> </span><span class="n">textureColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">textureSample</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">tex</span><span class="p">,</span><span class="w"> </span><span class="n">samp</span><span class="p">,</span><span class="w"> </span><span class="n">texcoords</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>This function can be used for <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> 1D, 2D, 3D, and cube textures. For a 1D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the texcoords parameter is an f32; for a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, it is a vec2f; and for a 3D or cube <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, it's a vec3f. The return value is a vec4f representing an <abbr title="An RGB color—specified by red, green, and blue component values—together with an alpha component. The alpha component is most often take to specify the degree of transparency of the color, with a maximal alpha value giving a fully opaque color.">RGBA color</abbr>. The return value is always a vec4f, even when the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> does not actually store four color components. For example, a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> might store just one <abbr title="One of the numbers used in a color model to specify a color. For example, in the RGB color model, a color is specified by three color components representing the amounts of red, green, and blue in the color.">color component</abbr>; when it is sampled using textureSample(), the color value from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> will be used as the red component of the color, the green and blue color components will be set to 0.0, and the <abbr title="An extra component (that is, one of the numbers that are used to specify a color) in a color model that is not part of the actual color specification. The alpha component is extra information. It is most often used to specify the degree of transparency of a color.">alpha</abbr> component will be 1.0.</p>
<p>You should now be able to understand the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> source code from the sample program. Most of the work is on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side, so the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> code is quite simple:</p>
<div class="highlight"><pre><span></span><code><span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">sampler</span><span class="p">;</span><span class="w">  </span><span class="c1">// Sampler resource from JavaScript.</span>
<span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">tex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">texture_2d</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span><span class="w">  </span><span class="c1">// Image texture resource.</span>

<span class="err">@</span><span class="nx">group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="nx">binding</span><span class="p">(</span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">textureSelect</span><span class="o">:</span><span class="w"> </span><span class="nx">u32</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// Value is 1, 2, or 3 to tell the fragment shader which texture to use.</span>

<span class="err">@</span><span class="nx">fragment</span>
<span class="nx">fn</span><span class="w"> </span><span class="nx">fragmentMain</span><span class="p">(</span><span class="err">@</span><span class="nx">location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">vec2f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="err">@</span><span class="nx">location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">textureSelect</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// Trivial procedural texture.</span>
<span class="w">        </span><span class="c1">// Use texcoords as red/green color components.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">vec4f</span><span class="p">(</span><span class="w"> </span><span class="nx">texcoords</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">1</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">textureSelect</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// For the checkerboard texture.</span>
<span class="w">        </span><span class="c1">// Apply texture transform: multiply texcoords by 5.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="mf">5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// For the Mona Lisa texture; no texture transform.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>Because of the limited options, textures and samplers are fairly simple to use in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program. Most of the work is on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side.</p>
<hr />
<p>The purpose of a sampler in <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> is to set options for the <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> process. Samplers are created using the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> function device.createSampler(). The following code creates a typical sampler for high-quality <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> of a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">sampler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createSampler</span><span class="p">({</span>
<span class="nx">addressModeU</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;repeat&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// Default is &quot;clamp-to-edge&quot;.</span>
<span class="nx">addressModeV</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;repeat&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">//    (The other possible value is &quot;mirror-repeat&quot;.)</span>
<span class="nx">minFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="nx">magFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span><span class="w">     </span><span class="c1">// Default for filters is &quot;nearest&quot;.</span>
<span class="nx">mipmapFilter</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
<span class="nx">maxAnisotropy</span><span class="o">:</span><span class="w"> </span><span class="mf">16</span><span class="w">        </span><span class="c1">// 1 is the default; 16 is the maximum.</span>
<span class="p">});</span>
</code></pre></div>
<p>The addressModeU property specifies how to treat values of the u <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinate that are outside the range 0 to 1, addressModeV does the same for the v coordinates, and for 3D textures there is also addressModeW. (In <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> and <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>, this was called "wrapping"; see <a href="../../c4/s3/#433-纹理目标和纹理参数">Subsection 4.3.3</a>. The meanings are the same here.)</p>
<p>Filtering accounts for the fact that an image usually has to be stretched or shrunk when it is applied to a surface. The magFilter, or <abbr title="An operation that is used when applying a texture to an object, when the texture has to be stretched to fit the object. For an image texture, a magnification filter is applied to compute the color of a pixel when that pixel covers just a fraction of a pixel in the image.">magnification filter</abbr>, is used when stretching an image. The minFilter, or <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr>, is used when shrinking it. <abbr title="一系列逐渐缩小尺寸的纹理图像副本，宽度和高度逐渐减小。从原始图像开始，每个mipmap通过将前一个图像的宽度和高度除以二（除非已经是1）来获得。最后的mipmap是一个单一像素。Mipmaps用于更有效地将纹理图像映射到表面上，当图像必须缩小以适应表面时。">Mipmaps</abbr> are reduced-size copies of the image that can make filtering more efficient. Textures don't automatically come with <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>; the mipmapFilter is ignored if no <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> are available. This is all similar to <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr>; see <a href="../../c4/s3/#432-mipmap-和过滤">Subsection 4.3.2</a>.</p>
<p>The maxAnisotropy property controls <abbr title="A technique for more accurate sampling of texture images, in the case where a pixel on the surface that is being textured corresponds to a non-rectangular region in the texture. Anisotropic filtering is available as an optional extension in WebGL.">anisotropic filtering</abbr>, which is explained in <a href="../../c7/s5/#751-各向异性过滤">Subsection 7.5.1</a>. The default value, 1, says that <abbr title="A technique for more accurate sampling of texture images, in the case where a pixel on the surface that is being textured corresponds to a non-rectangular region in the texture. Anisotropic filtering is available as an optional extension in WebGL.">anisotropic filtering</abbr> is not used. Higher values give better quality for textures that are viewed edge-on. The maximum value depends on the device, but it's OK to specify a value larger than the maximum; in that case, the maximum value will be used.</p>
<hr />
<p>Textures are created on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side using device.createTexture(). But it is important to understand that this function only allocates the memory on the <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> that will hold the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> data. The actual data will have to be stored later. This is similar to creating a <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> buffer. Here is how the checkerboard <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is created in the sample program:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">],</span><span class="w">  </span><span class="c1">// Two pixels wide by two pixels high.</span>
<span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;rgba8unorm&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// One 8-bit unsigned int for each color component.</span>
<span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span>
<span class="p">});</span>
</code></pre></div>
<p>This is a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, which is the default. The size property specifies the width and height of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, either as an array or as an object, {width: 2, height: 2}. The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> format specified here, "rgba8unorm", is a common one for images: four <abbr title="An RGB color—specified by red, green, and blue component values—together with an alpha component. The alpha component is most often take to specify the degree of transparency of the color, with a maximal alpha value giving a fully opaque color.">RGBA color</abbr> components for each <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, with 8 bits for each <abbr title="One of the numbers used in a color model to specify a color. For example, in the RGB color model, a color is specified by three color components representing the amounts of red, green, and blue in the color.">color component</abbr>. The "unorm" in the name means that the 8 bits represent unsigned integers in the range 0 to 255 which are scaled to the range 0.0 to 1.0 to give a floating-point color value. (The <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr> is referred to as "normalizing" the values—yet another meaning of the overworked term "normal.") In the usage property, TEXTURE_BINDING, means that the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can be sampled in a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program, and COPY_DST means that data can be copied into the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> from elsewhere. It is also possible to fill a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with data by attaching the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to a <abbr title="A sequence of computational stages in a GPU that are applied to incoming data to produce some result. Some of the stages can be programmable shaders, such as vertex shaders, fragment shaders, and compute shaders. In a graphics rendering pipeline, the output is the colors of the pixels in an image.">pipeline</abbr> as a render target; that requires the usage GPUTextureUsage.RENDER_ATTACHMENT. The other possible usage is COPY_SRC, which allows the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to be used as a source of copied data.</p>
<p>The size, format, and usage properties are required. There are a few optional properties. The mipLevelCount property specifies the number of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> that you will provide for the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. The default value, 1, means that only the main image will be provided. The dimension property can be "1d", "2d", or "3d", with a default of "2d". The sampleCount property has a default value of 1 and can be set to 4 to create a multisampled <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.</p>
<p>We have already used device.createTexture() to create the special purpose textures that are used for <abbr title="A kind of antialiasing where the fragment shader is evaluated at several points in each pixel, and the results are averaged to get the color of the pixel.">multisampling</abbr> and for the <abbr title="A solution to the hidden surface problem that involves keeping track of the depth, or distance from the viewer, of the object currently visible at each pixel in the image. When a new object is drawn at a pixel, the depth of the new object is compared to the depth of the current object to decide which one is closer to the viewer. The advantage of the depth test is that objects can be rendered in any order. A disadvantage is that only a limited range of depths can be represented in the image.">depth test</abbr>. See, for example, <a href="../../../en/source/webgpu/depth_test.html">webgpu/depth_test.html</a>. Those textures were used as render attachments, and the data for the textures were created by drawing an image.</p>
<p>Data for image textures often comes from the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side of the program. When the data comes from an <strong><em>ArrayBuffer</em></strong> or <abbr title="In JavaScript, an array type that is limited to holding numerical values of a single type. For example, the type Float32Array represents arrays that can hold 32-bit floating point values, and Uint8Array arrays can hold only 8-bit integer values. Such arrays are more efficient than general JavaScript arrays for numerical calculations. The were introduced into JavaScript along with HTML canvas graphics and WebGL.">typed array</abbr>, the data can be copied to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> using the function device.queue.writeTexture(). In the sample program, the data for the tiny checkerboard <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> comes from a <strong><em>Uint8Array</em></strong> and is copied to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with</p>
<div class="highlight"><pre><span></span><code><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">writeTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="w"> </span><span class="p">},</span><span class="w"> </span><span class="c1">// Texture to which data will be written.</span>
<span class="w">    </span><span class="nx">textureData</span><span class="p">,</span><span class="w">         </span><span class="c1">// A Uint8Array containing the data to be written.</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">bytesPerRow</span><span class="o">:</span><span class="w"> </span><span class="mf">8</span><span class="w"> </span><span class="p">},</span><span class="w">  </span><span class="c1">// How many bytes for each row of texels.</span>
<span class="w">    </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">]</span><span class="w">   </span><span class="c1">// Size of the texture (width and height).</span>
<span class="p">);</span>
</code></pre></div>
<p>The first parameter to writeTexture() is an object. In addition to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> property, the object can have a mipLevel property to copy the data into one of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>'s <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>, and an origin property to copy the data into a rectangular subregion within the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. (The origin can be given as an array of integers; together with the size parameter to the function, it determines the rectangular region.) The third parameter is also an object. The bytesPerRow property is the distance, in bytes, from the start of one row of texels to the start of the next row of texels. There can be padding between rows, which is sometimes necessary to satisfy alignment requirements. There can also be an offset property, giving the starting point, in bytes, of the data within the data source.</p>
<p>All of this might seem overly complicated, but textures and images are complex, and the functions that work with them can have many options.</p>
<hr />
<p>Often, the data source for a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is an image file. <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> cannot take the data directly from an image file; you have to fetch the file and extract the data into an <strong><em>ImageBitmap</em></strong> object. The fetch <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr>, which uses <abbr title="在 JavaScript 编程中，一个承诺代表一个可能立即可用或将来某个时候可用的结果。程序员可以提供一个函数，如果承诺实现（即结果可用时）或承诺被拒绝（例如，如果发生某些错误）时被调用。承诺是异步的，因为处理成功或失败的函数将在某个不可预测的时间被调用。">promises</abbr>, is discussed in <a href="../../a1/s4/">Section A.4</a>. Here, for example, is the function from <a href="../../../en/source/webgpu/textured_objects.html">textured_objects.html</a> that is used to load textures from image files:</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span><span class="w"> </span><span class="kd">function</span><span class="w"> </span><span class="nx">loadTexture</span><span class="p">(</span><span class="nx">URL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Standard method using the fetch API to get a texture from a ULR.</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">fetch</span><span class="p">(</span><span class="nx">URL</span><span class="p">);</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">blob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">response</span><span class="p">.</span><span class="nx">blob</span><span class="p">();</span><span class="w">  </span><span class="c1">// Get image data as a &quot;blob&quot;.</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">createImageBitmap</span><span class="p">(</span><span class="nx">blob</span><span class="p">);</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="w">        </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">],</span>
<span class="w">        </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">                    </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">copyExternalImageToTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">source</span><span class="o">:</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">,</span><span class="w"> </span><span class="nx">flipY</span><span class="o">:</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">]</span>
<span class="w">    </span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>'s usage property is required by copyExternalmageToTexture(). The flipY property is used because the program uses <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr>-style <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates on the objects that it displays. The source property could also be a canvas, as is done in <a href="../../../en/source/webgpu/texture_from_canvas.html">texture_from_canvas.html</a>. This loadTexture() function must be called from an <abbr title="In JavaScript, an async function is one that can use an &quot;await&quot; statement to wait for the result of a promise. When an await statement is executed, the execution of the async function is suspended until the promise has either been fulfilled or rejected, giving other JavaScript code a chance to run in the meantime.">async function</abbr> using await, and it is a good idea to catch the errors that might occur:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span>
<span class="k">try</span><span class="w"> </span><span class="p">{</span>
<span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">loadTexture</span><span class="p">(</span><span class="nx">URL</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="nx">e</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="p">...</span>
</code></pre></div>
<p>I will not discuss this in any more detail. See the sample programs for more examples.</p>
<hr />
<p>Samplers and textures that are created on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side must be passed to a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program as bind group resources. In the bind group, the resource for a sampler is the sampler itself, while the resource for a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is a view of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. Here for example is the bind group for the checkerboard <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> in <a href="../../../en/source/webgpu/first_texture.html">first_texture.html</a>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">checkerboardBindGroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="nx">bindGroupLayout</span><span class="p">,</span>
<span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w">    </span><span class="c1">// The sampler. Note that the resource is the sampler itself.</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardSampler</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w">    </span><span class="c1">// The texture.  Note that the resource is a view of the texture.</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">checkerboardTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w">    </span><span class="c1">// The resource is the buffer containing the uniform variable.</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">2</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="nx">buffer</span><span class="o">:</span><span class="w"> </span><span class="nx">uniformBuffer</span><span class="p">,</span><span class="w"> </span><span class="nx">offset</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="mf">4</span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
</div>
</div>
</div>
<h2 id="953-mipmap">9.5.3 Mipmap<a class="headerlink" href="#953-mipmap" title="Permanent link">&para;</a></h2>
<p><strong><abbr title="一系列逐渐缩小尺寸的纹理图像副本，宽度和高度逐渐减小。从原始图像开始，每个mipmap通过将前一个图像的宽度和高度除以二（除非已经是1）来获得。最后的mipmap是一个单一像素。Mipmaps用于更有效地将纹理图像映射到表面上，当图像必须缩小以适应表面时。">Mipmaps</abbr></strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">中文</label><label for="__tabbed_4_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><abbr title="一系列逐渐缩小尺寸的纹理图像副本，宽度和高度逐渐减小。从原始图像开始，每个mipmap通过将前一个图像的宽度和高度除以二（除非已经是1）来获得。最后的mipmap是一个单一像素。Mipmaps用于更有效地将纹理图像映射到表面上，当图像必须缩小以适应表面时。">Mipmaps</abbr> 在纹理需要“缩小”以适应表面时对质量和效率至关重要。使用 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 时，mip 级别 0 是原始图像，mip 级别 1 是半尺寸副本，mip 级别 2 是四分之一尺寸副本，依此类推。确切地说，如果 width 是原始图像的宽度，那么 mip 级别 i 的宽度是 <code>max(1, width &gt;&gt; i)</code>，高度也是如此。对于完整的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 集合，该过程会一直持续到所有尺寸都减小到 1。</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 没有自动生成 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 的方法，但在 <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr> 上编写一个 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 程序来创建它们并不难。示例程序 <a href="../../../en/source/webgpu/making_mipmaps.html">webgpu/making_mipmaps.html</a> 展示了如何做到这一点。它定义了一个函数，可以用来从 <strong><em>ImageBitmap</em></strong> 创建具有完整 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 集合的纹理。该程序还作为渲染到纹理和使用纹理视图的示例。</p>
<p>创建纹理时，必须指定 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 的数量。给定用于级别 0 的图像位图，很容易计算出完整集合所需的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 数量：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Math</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">);</span>
<span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="nx">size</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">mipmapCount</span><span class="o">++</span><span class="p">;</span>
<span class="w">    </span><span class="nx">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">size</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="w">    </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">],</span>
<span class="w">    </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="p">,</span><span class="w"> </span><span class="c1">// mipmaps 的数量。</span>
<span class="w">    </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">    </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">            </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="p">});</span>
</code></pre></div>
<p>可以使用 <code>copyExternalImageToTexture()</code> 函数将位图复制到纹理的级别 0，方法与往常一样。然后，每个剩余的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 图像可以依次生成，方法是对前一个级别图像进行半尺寸复制。方法是将 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 作为管线的渲染目标附加，并使用前一个 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 级别作为管线的纹理资源。然后绘制一个正方形，它刚好覆盖输出，其纹理坐标将整个资源图像映射到输出上。</p>
<p>回想一下，纹理资源和渲染目标实际上是纹理的视图。我们一直在使用 <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.createView()，不带参数，来创建纹理视图。结果是包括纹理所拥有的所有 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 的视图。但是，通过向 createView() 传递一个参数来创建一个只包含可用 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 子集的视图是可能的，该参数指定了要包含在视图中的第一个 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 以及要包含的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> 数量。创建只包含 mip 级别 i 的视图：</p>
<div class="highlight"><pre><span></span><code><span class="nx">textureView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span>
<span class="w">    </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">i</span><span class="p">,</span><span class="w">  </span><span class="c1">// 包含在此视图中的第一个 mipmap 级别。</span>
<span class="w">    </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w">  </span><span class="c1">// 只包括一个 mipmap 级别。</span>
<span class="p">});</span>
</code></pre></div>
<p>这将允许我们使用单个纹理的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 作为纹理资源或渲染目标。这里，例如，是示例程序中创建 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 图像的循环：</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kd">let</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="p">;</span><span class="w"> </span><span class="nx">mipmap</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">inputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">(</span><span class="w">  </span><span class="c1">// 用作绑定组资源。</span>
<span class="w">                            </span><span class="p">{</span><span class="w"> </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">outputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">(</span><span class="w"> </span><span class="c1">// 用作渲染目标。</span>
<span class="w">                            </span><span class="p">{</span><span class="w"> </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmap</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">renderPassDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">colorAttachments</span><span class="o">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">            </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;load&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="nx">outputView</span><span class="w">  </span><span class="c1">// 渲染到 mipmap。</span>
<span class="w">        </span><span class="p">}]</span>
<span class="w">    </span><span class="p">};</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">bindGroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">webgpuDevice</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="w">        </span><span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="nx">pipeline</span><span class="p">.</span><span class="nx">getBindGroupLayout</span><span class="p">(</span><span class="mf">0</span><span class="p">),</span>
<span class="w">        </span><span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">sampler</span><span class="w"> </span><span class="p">},</span>
<span class="w">                    </span><span class="p">{</span><span class="w"> </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">inputView</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">]</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">passEncoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">commandEncoder</span><span class="p">.</span><span class="nx">beginRenderPass</span><span class="p">(</span><span class="nx">renderPassDescriptor</span><span class="p">);</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setPipeline</span><span class="p">(</span><span class="nx">pipeline</span><span class="p">);</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setVertexBuffer</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span><span class="nx">vertexBuffer</span><span class="p">);</span><span class="w"> </span><span class="c1">// 坐标和纹理坐标。</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setBindGroup</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span><span class="nx">bindGroup</span><span class="p">);</span><span class="w"> </span><span class="c1">// 包括前一个 mipmap 级别。</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">draw</span><span class="p">(</span><span class="mf">4</span><span class="p">);</span><span class="w"> </span><span class="c1">// 作为三角形条带绘制正方形。</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">end</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p><abbr title="一系列逐渐缩小尺寸的纹理图像副本，宽度和高度逐渐减小。从原始图像开始，每个mipmap通过将前一个图像的宽度和高度除以二（除非已经是1）来获得。最后的mipmap是一个单一像素。Mipmaps用于更有效地将纹理图像映射到表面上，当图像必须缩小以适应表面时。">Mipmaps</abbr> are important for quality and efficiency when a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has to be "minified" to fit a surface. When working with <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>, mip level 0 is the original image, mip level 1 is a half-size copy, mip level 2 is a quarter-size copy, and so on. To be exact, if width is the width of the original image, then the width of mip level i is <code>max(1, width &gt;&gt; i)</code>, and similarly for the height. For a full set of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>, the process continues until all dimensions have been reduced to 1.</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> has no method for automatically generating <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>, but it is not hard to write a <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> program to create them on the <abbr title="Graphics Processing Unit, a computer hardware component that performs graphical computations that create and manipulate images. Operations such as drawing a line on the screen or rendering a 3D image are done in the GPU, which is optimized to perform such operations very quickly.">GPU</abbr>. The sample program <a href="../../../en/source/webgpu/making_mipmaps.html">webgpu/making_mipmaps.html</a> shows how to do this. It defines a function that can be used to create a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with a full set of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> from an <strong><em>ImageBitmap</em></strong>. The program also serves as an example of <abbr title="The process of producing a 2D image from a 3D scene description.">rendering</abbr> to a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> and using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> views.</p>
<p>When creating a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the number of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> must be specified. It is easy to count the number of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> needed for a full set, given the image bitmap that will be used for level 0:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Math</span><span class="p">.</span><span class="nx">max</span><span class="p">(</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">);</span>
<span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="nx">size</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">mipmapCount</span><span class="o">++</span><span class="p">;</span>
<span class="w">    </span><span class="nx">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">size</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span>
<span class="w">    </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">],</span>
<span class="w">    </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="p">,</span><span class="w"> </span><span class="c1">// Number of mipmaps.</span>
<span class="w">    </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">    </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">                </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="p">});</span>
</code></pre></div>
<p>The function <code>copyExternalImageToTexture()</code> can be used to copy the bitmap to level 0 in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> in the usual way. Then each of the remaining <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> images can be generated in turn by making a half-size copy of the previous level image. The idea is to attach the <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> as the render target of a <abbr title="A sequence of computational stages in a GPU that are applied to incoming data to produce some result. Some of the stages can be programmable shaders, such as vertex shaders, fragment shaders, and compute shaders. In a graphics rendering pipeline, the output is the colors of the pixels in an image.">pipeline</abbr> and use the previous <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> level as a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> resource for the <abbr title="A sequence of computational stages in a GPU that are applied to incoming data to produce some result. Some of the stages can be programmable shaders, such as vertex shaders, fragment shaders, and compute shaders. In a graphics rendering pipeline, the output is the colors of the pixels in an image.">pipeline</abbr>. Then draw a square that just covers the output, with <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates that map the entire resource image onto the output.</p>
<p>Recall that <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> resources and render targets are actually views of textures. We have been using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.createView(), with no parameter, to create <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> views. The result is a view that includes all the <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> that the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has. But it is possible to create a view that contains just a subset of available <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> by passing a parameter to createView() that specifies the first <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> and the number of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> to include in the view. To create a view the contains only mip level i:</p>
<div class="highlight"><pre><span></span><code><span class="nx">textureView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span>
<span class="w">    </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">i</span><span class="p">,</span><span class="w">  </span><span class="c1">// First mip level included in this view.</span>
<span class="w">    </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w">  </span><span class="c1">// Only include one mip level.</span>
<span class="p">});</span>
</code></pre></div>
<p>This will let us use a single <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> from a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> as a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> resource or render target. Here, for example, is the loop from the sample program that creates the <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> images:</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kd">let</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1</span><span class="p">;</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nx">mipmapCount</span><span class="p">;</span><span class="w"> </span><span class="nx">mipmap</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">inputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">(</span><span class="w">  </span><span class="c1">// Used as a bind group resource.</span>
<span class="w">                            </span><span class="p">{</span><span class="w"> </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmap</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">outputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture</span><span class="p">.</span><span class="nx">createView</span><span class="p">(</span><span class="w"> </span><span class="c1">// Used as a render target.</span>
<span class="w">                            </span><span class="p">{</span><span class="w"> </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="nx">mipmap</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">renderPassDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">colorAttachments</span><span class="o">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">        </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;load&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">        </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="nx">outputView</span><span class="w">  </span><span class="c1">// Render to mipmap.</span>
<span class="w">    </span><span class="p">}]</span>
<span class="w">    </span><span class="p">};</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">bindGroup</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">webgpuDevice</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="w">    </span><span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="nx">pipeline</span><span class="p">.</span><span class="nx">getBindGroupLayout</span><span class="p">(</span><span class="mf">0</span><span class="p">),</span>
<span class="w">    </span><span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">sampler</span><span class="w"> </span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="w"> </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="mf">1</span><span class="p">,</span><span class="w"> </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="nx">inputView</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">]</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">passEncoder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">commandEncoder</span><span class="p">.</span><span class="nx">beginRenderPass</span><span class="p">(</span><span class="nx">renderPassDescriptor</span><span class="p">);</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setPipeline</span><span class="p">(</span><span class="nx">pipeline</span><span class="p">);</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setVertexBuffer</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span><span class="nx">vertexBuffer</span><span class="p">);</span><span class="w"> </span><span class="c1">// Coords and texcoords.</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">setBindGroup</span><span class="p">(</span><span class="mf">0</span><span class="p">,</span><span class="nx">bindGroup</span><span class="p">);</span><span class="w"> </span><span class="c1">// Includes previous mipmap level.</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">draw</span><span class="p">(</span><span class="mf">4</span><span class="p">);</span><span class="w"> </span><span class="c1">// Draw square as a triangle-strip.</span>
<span class="w">    </span><span class="nx">passEncoder</span><span class="p">.</span><span class="nx">end</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div>
</div>
</div>
</div>
<h2 id="954-立方体贴图纹理">9.5.4 立方体贴图纹理<a class="headerlink" href="#954-立方体贴图纹理" title="Permanent link">&para;</a></h2>
<p><strong>Cubemap Textures</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">中文</label><label for="__tabbed_5_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>立方体贴图由六张图像组成，每张图像对应立方体的每个面。这些图像必须是正方形，并且大小必须相同。立方体贴图可以用于创建天空盒（见<a href="../../c5/s3/#534-立方体贴图纹理和天空盒">5.3.4小节</a>）和环境映射（也称为反射映射，见<a href="../../c7/s3/#735-环境映射">7.3.5小节</a>）。示例程序 <a href="../../../en/source/webgpu/cubemap_texture.html">webgpu/cubemap_texture.html</a> 展示了如何在 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 中创建立方体贴图以及如何将其用于天空盒和环境映射。它在功能上与 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 示例 <a href="../../../en/source/webgl/skybox-and-env-map.html">webgl/<abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>-and-env-map.html</a> 相同。</p>
<p>除了 "2d" <abbr title="应用于表面的图像，看起来就像是“画”在表面上。">图像纹理</abbr>，<abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 还有 "2d-array" <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>。2d-array 纹理就是一个 2d 图像的数组。数组中的元素称为 "层"。我并没有在这本教科书中涵盖数组纹理，但你需要知道一些关于它们的信息，因为出于某些目的，立方体贴图被视为具有六层的数组。索引 0 到 5 的图像分别是立方体的 +X、-X、+Y、-Y、+Z 和 -Z 面，按此顺序。特别是，在创建纹理和加载六个面的图像时，立方体贴图被视为一个数组。以下是示例程序中加载纹理的一些（编辑过的）代码：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">urls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="w">  </span><span class="c1">// 立方体贴图的六张图像链接。</span>
<span class="w">    </span><span class="s2">&quot;cubemap-textures/park/posx.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negx.jpg&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;cubemap-textures/park/posy.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negy.jpg&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;cubemap-textures/park/posz.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negz.jpg&quot;</span>
<span class="p">];</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span><span class="w"> </span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kd">let</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">6</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">fetch</span><span class="p">(</span><span class="w"> </span><span class="nx">urls</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">);</span><span class="w"> </span><span class="c1">// 获取第 i 张图像。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">blob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">response</span><span class="p">.</span><span class="nx">blob</span><span class="p">();</span><span class="w"> </span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">createImageBitmap</span><span class="p">(</span><span class="nx">blob</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// （我们需要知道图像大小才能创建纹理。）</span>
<span class="w">        </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span><span class="w"> </span>
<span class="w">            </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">,</span><span class="w"> </span><span class="mf">6</span><span class="p">],</span>
<span class="w">                </span><span class="c1">// （最后的 6 表示有 6 张图像。）</span>
<span class="w">            </span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// （这是默认的纹理维度。）</span>
<span class="w">            </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUTextureUsage.TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">                    </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="w">        </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">copyExternalImageToTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">source</span><span class="o">:</span><span class="w"> </span><span class="kt">imageBitmap</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="kt">texture</span><span class="p">,</span><span class="w">  </span><span class="nx">origin</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="c1">// 最后的 i 将图像放入立方体的第 i 个面。</span>
<span class="w">    </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">]</span>
<span class="w">    </span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>对于维度为 "2d" 的纹理，size 属性的第三个元素使纹理成为数组纹理。（对于 "3d" <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，第三个元素将是 z 方向上的大小。）类似地，当将图像复制到纹理中时，origin 属性的第三个元素指定了要将图像复制到的数组层。</p>
<p>（当我第一次使用上述代码编写程序时，环境映射看起来与 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 版本相比非常糟糕。这在像茶壶把手这样的急剧弯曲表面上最为明显。最终，我意识到不同之处在于 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 版本使用了 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr>。因此，我为 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 版本添加了代码，以为立方体贴图生成 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr>。我还添加了一个选项来打开和关闭 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 的使用，以便你可以看到差异。）</p>
<hr />
<p>在 <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> 着色器程序中，立方体贴图的使用与 2D 纹理类似。立方体贴图的数据类型是 <code>texture_cube&lt;f32&gt;</code>。采样纹理时，与 2D 纹理一样使用 <code>textureSample()</code> 函数，但第三个参数，提供纹理坐标的是 vec3f。通过在 vec3f 的方向上投射光线，并查看它与立方体的交点来获取样本。对于天空盒，基本上显示从盒子内部的视图，纹理坐标就是盒子上某点的对象坐标。因此，绘制天空盒背景的片段着色器非常简单：</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="o">:</span><span class="w"> </span><span class="kt">sampler</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">cubeTex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">texture_cube</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@fragment</span><span class="w"> </span><span class="nx">fn</span><span class="w"> </span><span class="nx">fmain</span><span class="p">(</span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">objCoords</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="nx">cubeTex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">objCoords</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>对于环境映射，思路是从观察者向反射物体上的某点投射光线，并使用该光线从表面的反射作为纹理坐标向量：反射光线击中天空盒的点将是用户在反射物体上看到的点。由于示例程序中的天空盒可以旋转，因此必须调整射线的方向以考虑这种旋转。见 <a href="../../c7/s3/#735-环境映射">7.3.5小节</a> 了解完整的数学讨论。以下是绘制反射物体的片段着色器：</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="o">:</span><span class="w"> </span><span class="kt">sampler</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">cubeTex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">texture_cube</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">mat3x3f</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">3</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">mat3x3f</span><span class="p">;</span>
<span class="kd">@fragment</span><span class="w"> </span><span class="nx">fn</span><span class="w"> </span><span class="nx">fmain</span><span class="p">(</span>
<span class="w">        </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="p">,</span><span class="w"> </span><span class="c1">// 观察者到表面的方向。</span>
<span class="w">        </span><span class="kd">@location</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="nx">normal</span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="w"> </span><span class="c1">// 表面未变换的法向量。</span>
<span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">normal</span><span class="p">);</span><span class="w"> </span><span class="c1">// 表面法向量。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">reflect</span><span class="p">(</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">,</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="p">);</span><span class="w">  </span><span class="c1">// 反射方向（朝向天空盒）。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">R</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="c1">// 乘以视图变换的逆矩阵以考虑天空盒的旋转。</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="nx">cubeTex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">T</span><span class="p">);</span><span class="w"> </span><span class="c1">// 使用反射光线进行采样。</span>
<span class="p">}</span>
</code></pre></div>
<p>在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端，立方体贴图的使用与 2D 纹理类似。用于立方体贴图的采样器与用于 2D 纹理的采样器相同。并将立方体贴图的视图作为绑定组资源传递给着色器程序。一个区别是，在创建视图时，需要指定要将纹理视为立方体贴图：</p>
<div class="highlight"><pre><span></span><code><span class="nx">cubeTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;cube&quot;</span><span class="p">})</span>
</code></pre></div>
<p>默认情况下，它将被视为 2d 数组纹理。在为纹理创建 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 时，我需要视图来表示立方体单个面的单个 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 级别。例如，</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">outputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">cubeTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span>
<span class="w">    </span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="kt">mipmap</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">    </span><span class="nx">baseArrayLayer</span><span class="o">:</span><span class="w"> </span><span class="kt">side</span><span class="p">,</span><span class="w"> </span><span class="nx">arrayLayerCount</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span>
<span class="p">});</span>
</code></pre></div>
<p>其中 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 是所需的 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 级别，side 是立方体所需面的数组索引。维度必须明确指定为 "2d"。（所有这些可能帮助你理解纹理和纹理视图之间的区别。）</p>
</div>
<div class="tabbed-block">
<p>A <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> consists of six images, one for each side of a cube. The images must be square and must all be the same size. A <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> can be used, for example, to make a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> (<a href="../../c5/s3/#534-立方体贴图纹理和天空盒">Subsection 5.3.4</a>) and to do <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr> (also called <abbr title="Another name for environment mapping.">reflection mapping</abbr>, <a href="../../c7/s3/#735-环境映射">Subsection 7.3.5</a>). The sample program <a href="../../../en/source/webgpu/cubemap_texture.html">webgpu/cubemap_texture.html</a> shows how to create a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> in <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> and how to use it for a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> and for <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr>. It is functionally identical to the <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> example <a href="../../../en/source/webgl/skybox-and-env-map.html">webgl/<abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>-and-env-map.html</a>.</p>
<p>In addition to "2d" image textures, <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> has "2d-array" textures. A 2d-array <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is just that—an array of 2d images. The elements of the array are called "layers". I do not cover array textures in this textbook, but you need to know a little about them since, for some purposes, a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is treated as an array with six layers. The images at indices 0 through 5 are the +X, -X, +Y, -Y, +Z, and -Z sides of the cube, in that order. In particular, a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is treated as an array when creating the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> and loading the images for the six sides. Here is some (edited) code from the sample program for loading the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">urls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="w">  </span><span class="c1">// Links to the six images for the cube.</span>
<span class="s2">&quot;cubemap-textures/park/posx.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negx.jpg&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="s2">&quot;cubemap-textures/park/posy.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negy.jpg&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="s2">&quot;cubemap-textures/park/posz.jpg&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cubemap-textures/park/negz.jpg&quot;</span>
<span class="p">];</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">texture</span><span class="p">;</span><span class="w"> </span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kd">let</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">6</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">fetch</span><span class="p">(</span><span class="w"> </span><span class="nx">urls</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">);</span><span class="w"> </span><span class="c1">// Get image number i.</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">blob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">response</span><span class="p">.</span><span class="nx">blob</span><span class="p">();</span><span class="w"> </span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">await</span><span class="w"> </span><span class="nx">createImageBitmap</span><span class="p">(</span><span class="nx">blob</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// (We need to know the image size to create the texture.)</span>
<span class="w">        </span><span class="nx">texture</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createTexture</span><span class="p">({</span><span class="w"> </span>
<span class="w">            </span><span class="nx">size</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">,</span><span class="w"> </span><span class="mf">6</span><span class="p">],</span>
<span class="w">                </span><span class="c1">// (The 6 at the end means that there are 6 images.)</span>
<span class="w">            </span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// (This is the default texture dimension.)</span>
<span class="w">            </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;rgba8unorm&#39;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">usage</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUTextureUsage.TEXTURE_BINDING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">COPY_DST</span><span class="w"> </span><span class="o">|</span>
<span class="w">                        </span><span class="nx">GPUTextureUsage</span><span class="p">.</span><span class="nx">RENDER_ATTACHMENT</span>
<span class="w">        </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nx">device</span><span class="p">.</span><span class="nx">queue</span><span class="p">.</span><span class="nx">copyExternalImageToTexture</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">source</span><span class="o">:</span><span class="w"> </span><span class="kt">imageBitmap</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="kt">texture</span><span class="p">,</span><span class="w">  </span><span class="nx">origin</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">,</span><span class="w"> </span><span class="nx">i</span><span class="p">]</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="c1">// The i at the end puts the image into side number i of the cube.</span>
<span class="w">    </span><span class="p">[</span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span><span class="w"> </span><span class="nx">imageBitmap</span><span class="p">.</span><span class="nx">height</span><span class="p">]</span>
<span class="w">    </span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>For a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with dimension "2d", the third element in the size property makes the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> into an array <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. (For a "3d" <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the third element would be the size in the z direction.) Similarly, when copying an image into the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the third element of the origin property specifies the array layer into which the image is to be copied.</p>
<p>(When I first wrote the program, using the above code, the <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr> looked really bad, compared to the <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> version. This was most apparent on sharply curved surfaces such as the handle of the teapot. Eventually, I realized that the difference was that the <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> version uses <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr>. So, I added code to the <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> version to produce <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> for the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. I also added an option to turn the use of <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> on and off, so that you can see the difference.)</p>
<hr />
<p>In a <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program, cubemap textures are used similarly to 2D textures. The data type for a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is <code>texture_cube&lt;f32&gt;</code>. For <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the same <code>textureSample()</code> function is used as for 2D textures, but the third parameter, which gives the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, is a vec3f. The sample is obtained by casting a ray from the origin in the direction of the vec3f, and seeing where it intersects the cube. For a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, which basically shows the view of the box from the inside, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are just the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> of a point on the box. So, the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> for drawing the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> background is simply</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="o">:</span><span class="w"> </span><span class="kt">sampler</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">cubeTex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">texture_cube</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@fragment</span><span class="w"> </span><span class="nx">fn</span><span class="w"> </span><span class="nx">fmain</span><span class="p">(</span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">objCoords</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="nx">cubeTex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">objCoords</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>For <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr>, the idea is to cast a ray from the viewer to a point on the reflective object, and use the reflection of that ray from the surface as the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinate <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>: The point where the reflected ray hits the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> is the point that will be seen by the user on the reflective object. Since the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> in the sample program can be rotated, the direction of the ray has to be adjusted to take that <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr> into account. See <a href="../../c7/s3/#735-环境映射">Subsection 7.3.5</a> for a full discussion of the math. Here is the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> for drawing the reflected object:</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">samp</span><span class="o">:</span><span class="w"> </span><span class="kt">sampler</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">cubeTex</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">texture_cube</span><span class="o">&lt;</span><span class="nx">f32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">2</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">mat3x3f</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">3</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="o">&lt;</span><span class="nx">uniform</span><span class="o">&gt;</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">mat3x3f</span><span class="p">;</span>
<span class="kd">@fragment</span><span class="w"> </span><span class="nx">fn</span><span class="w"> </span><span class="nx">fmain</span><span class="p">(</span>
<span class="w">            </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="p">,</span><span class="w"> </span><span class="c1">// Direction from viewer to surface.</span>
<span class="w">            </span><span class="kd">@location</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="nx">normal</span><span class="o">:</span><span class="w"> </span><span class="kt">vec3f</span><span class="w"> </span><span class="c1">// Untransformed normal to surface.</span>
<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">normal</span><span class="p">);</span><span class="w"> </span><span class="c1">// Normal vector to the surface.</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">reflect</span><span class="p">(</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">,</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="p">);</span><span class="w">  </span><span class="c1">// Reflected direction (towards skybox).</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">R</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="c1">// Multiplying by inverse of the view transform accounts</span>
<span class="w">        </span><span class="c1">//    for the rotation of the skybox.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">textureSample</span><span class="p">(</span><span class="nx">cubeTex</span><span class="p">,</span><span class="w"> </span><span class="nx">samp</span><span class="p">,</span><span class="w"> </span><span class="nx">T</span><span class="p">);</span><span class="w"> </span><span class="c1">// Use reflected ray to sample.</span>
<span class="p">}</span>
</code></pre></div>
<p>On the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side, again, cubemap textures are used similarly to 2D textures. The samplers that are used for cubemap textures are the same as those used for 2D textures. And a view of the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is passed to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program as a bind group resource. One difference is that when creating a view, you need to specify that you want to view the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> as a cube <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">cubeTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;cube&quot;</span><span class="p">})</span>
</code></pre></div>
<p>By default, it would be viewed as a 2d array <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. When creating <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmaps</abbr> for the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, I needed views of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to represent a single <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> level of a single side of the cube. For example,</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">outputView</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">cubeTexture</span><span class="p">.</span><span class="nx">createView</span><span class="p">({</span>
<span class="w">                    </span><span class="nx">dimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nx">baseMipLevel</span><span class="o">:</span><span class="w"> </span><span class="kt">mipmap</span><span class="p">,</span><span class="w"> </span><span class="nx">mipLevelCount</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">                    </span><span class="nx">baseArrayLayer</span><span class="o">:</span><span class="w"> </span><span class="kt">side</span><span class="p">,</span><span class="w"> </span><span class="nx">arrayLayerCount</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span>
<span class="w">                </span><span class="p">});</span>
</code></pre></div>
<p>where <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> is the desired <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> level and side is the array index for the desired side of the cube. The dimension must be explicitly specified as "2d". (All this might help you understand the difference between a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> and a view of a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.)</p>
</div>
</div>
</div>
<h2 id="955-纹理格式">9.5.5 纹理格式<a class="headerlink" href="#955-纹理格式" title="Permanent link">&para;</a></h2>
<p><strong>Texture Formats</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="6:2"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">中文</label><label for="__tabbed_6_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>纹理的格式指定了每个 texels 存储的数据类型。格式指定了颜色通道的数量、数据类型，并且在某些情况下还指定了数据的解释方式。在常见的 2D 图像格式 "rgba8unorm" 中，有四个颜色通道（"r"、"g"、"b" 和 "a"）。一个 texels 的数据由每个颜色通道的 8 位组成。颜色通道的值是一个无符号整数（"u"），范围在 0 到 255 之间，除以 255 得到范围在 0.0 到 1.0 之间的浮点值（"norm"）。格式 "bgra8unorm" 类似，但 "r"、"g" 和 "b" 值的顺序相反。（这两种格式中的一种，根据平台的不同，是 <abbr title="HyperText Markup Language. A language that is used for specifying the content of web pages. An HTML document is made up of text, along with &quot;elements&quot; for adding other content, such as images, and for defining the structure of the document. Because of nesting of elements, the document can be represented by a tree-like data structure.">HTML</abbr> 画布的格式；函数 navigator.gpu.getPreferredCanvasFormat() 返回适合您平台的正确格式。然而，使用错误的格式并不会使您的程序停止工作，因为 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 在读写纹理时会自动进行一些格式转换。）</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 支持大量的纹理格式。有具有一个颜色通道 ("r")、两个颜色通道 ("rg") 和四个颜色通道 ("rgba") 的格式。每个颜色通道的位数可以是 8、16 或 32。数据类型可以是浮点数、无符号整数或有符号整数。一些整数格式是归一化的，但大多数不是。（还有压缩纹理格式，本教科书未涵盖。）</p>
<p>例如，格式 "r8uint"、"r16uint" 和 "r32uint" 是具有一个颜色通道的无符号整数格式，每个 texels 存储一个 8 位、16 位或 32 位的无符号整数。对于每个 texels 的两个 16 位有符号整数，格式将是 "rg16sint"。格式 "rgba32float" 每个 texels 使用四个 32 位浮点数。</p>
<p>所有纹理都可以作为资源通过绑定组传递到着色器程序中，但只有浮点纹理才能使用 textureSample() 进行采样。（这包括归一化整数格式。）然而，标准 <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> 函数 textureLoad() 可以用于从纹理中读取 texels 数据，它既适用于整数纹理，也适用于浮点纹理。这个函数将纹理视为一个数组：不是使用纹理坐标来采样纹理，而是使用整数 texels 坐标来访问指定 texels 的值。例如，要从 <code>texture_2d&lt;u32&gt;</code> 的第 7 行、第 15 列的 texels 读取，可以使用</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">texelValue</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec4u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureLoad</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="mf">7</span><span class="p">,</span><span class="mf">15</span><span class="p">),</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>第三个参数是 <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> 级别，这是必需的，但通常为零。</p>
<p><code>textureLoad()</code> 的返回值始终是一个 4 组件向量，即使纹理只有一个或两个颜色通道。缺失的颜色通道用 "g" 或 "b" 通道的 0 <abbr title="绘制形状的内部，通过着色位于形状内部的像素。填充不适用于没有内部的形状，例如线段。">填充</abbr>，"a" 通道用 1 <abbr title="绘制形状的内部，通过着色位于形状内部的像素。填充不适用于没有内部的形状，例如线段。">填充</abbr>。（请注意，即使纹理中的值可能不代表颜色，整数纹理仍使用 "color" 一词。浮点纹理也可以存储除颜色之外的数据。）</p>
<p>着色器程序也可以使用 <code>textureStore()</code> 函数将 texels 数据写入纹理。然而，纹理必须作为所谓的 "storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>" 传递到着色器中，而这仅适用于某些纹理格式。（关于各种纹理格式可以执行的操作有很多规则。这些规则在 <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> 规范的第 26.1 节的纹理格式功能表中进行了总结。）</p>
<p>在着色器中，存储纹理的类型如 <code>texture_storage_2d&lt;r32uint,write&gt;</code>。第一个类型参数 r32uint 是纹理格式，第二个参数 write 指定了访问模式。（目前，write 是唯一的可能性。）纹理作为类型为 textureStorage 的绑定组资源传递到着色器中，而不是 <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>。例如，以下是使用两个 r32uint 纹理的着色器程序的绑定组布局，一个用于使用 <code>textureLoad()</code> 读取，一个用于使用 <code>textureStore()</code> 写入：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">bindGroupLayout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroupLayout</span><span class="p">({</span>
<span class="w">    </span><span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span><span class="w">    </span><span class="c1">// 用于片段着色器中的 texture_2d&lt;u32&gt; 变量</span>
<span class="w">            </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span>
<span class="w">            </span><span class="nx">visibility</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUShaderStage.FRAGMENT</span><span class="p">,</span>
<span class="w">            </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nx">sampleType</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;uint&quot;</span><span class="w">  </span><span class="c1">// Texels 值是无符号整数。</span>
<span class="w">                </span><span class="c1">// （是的，尽管你不能采样它，它仍被称为 sampleType！）</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span><span class="w">    </span><span class="c1">// 用于片段着色器中的 texture_storage_2d&lt;r32uint,write&gt;</span>
<span class="w">            </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">            </span><span class="nx">visibility</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUShaderStage.FRAGMENT</span><span class="p">,</span>
<span class="w">            </span><span class="nx">storageTexture</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;r32uint&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nx">access</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;write-only&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// 这是唯一可能的值。</span>
<span class="w">                </span><span class="nx">viewDimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="w">    </span><span class="c1">// 这是默认值。</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
<p>请注意 "storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>" 只意味着作为类型为 textureStorage 的绑定组资源传递到着色器的纹理。同一个纹理可以作为常规纹理或存储纹理使用，或者在不同的时间两者都使用。</p>
<p><code>textureStore()</code> 函数接受三个参数：<abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>、要设置值的 texels 坐标和值。值始终是一个 4 组件向量，即使纹理少于四个颜色通道。缺失的通道应指定为 "g" 或 "b" 通道的 0，"a" 通道的 1。例如，要在 2D r32uint 存储纹理的第 7 行、第 15 列设置单个整数值 17，可以使用</p>
<div class="highlight"><pre><span></span><code><span class="nx">textureStore</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="mf">7</span><span class="p">,</span><span class="mf">15</span><span class="p">),</span><span class="w"> </span><span class="nx">vec4u</span><span class="p">(</span><span class="mf">17</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<hr />
<p>示例程序 <a href="../../../en/source/webgpu/life_1.html">webgpu/life_1.html</a> 实现了 John Conway 的著名生命游戏（见 <a href="../../c6/s4/#645-计算示例">6.4.5小节</a>）。游戏棋盘是一个 2D 单元格数组，每个单元格可以是活的或死的。在程序中，棋盘的状态存储为类型为 r32uint 的 2D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>，其中 0 表示死亡的细胞，1 表示活的细胞。游戏棋盘显示在画布上，画布上的每个像素都是一个细胞。因此，纹理的大小与画布的大小相同。</p>
<p>游戏的动作涉及从当前一代计算出新一代的细胞。程序实际上使用两个纹理：一个常规纹理包含当前一代的棋盘和一个存储纹理，用于存储计算出的下一代。程序的所有工作都在其 draw() 函数中完成。该函数绘制一个完全覆盖画布的正方形，以便为画布上的每个像素调用一次片段着色器。片段着色器使用 textureLoad() 读取它正在处理的细胞的当前状态。如果细胞是活的，它返回白色作为片段的颜色；如果细胞是死的，它返回黑色。同时，片段着色器计算细胞在下一代的状态，并使用 textureStore() 将该状态写入存储纹理。在绘制之间，两个纹理的角色被交换，因此下一代成为当前一代。</p>
<p>以下是片段着色器，省略了计算细胞新状态的部分。它使用另一个新函数 textureDimensions()，该函数获取纹理在每个维度上的大小。这个值是新状态计算所需的。</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">inputBoard</span><span class="o">:</span><span class="w"> </span><span class="kt">texture_2d</span><span class="o">&lt;</span><span class="nx">u32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">outputBoard</span><span class="o">:</span><span class="w"> </span><span class="kt">texture_storage_2d</span><span class="o">&lt;</span><span class="nx">r32uint</span><span class="p">,</span><span class="nx">write</span><span class="o">&gt;</span><span class="p">;</span>

<span class="kd">@fragment</span>
<span class="nx">fn</span><span class="w"> </span><span class="nx">fragmentMain</span><span class="p">(</span><span class="kd">@builtin</span><span class="p">(</span><span class="nx">position</span><span class="p">)</span><span class="w"> </span><span class="nx">position</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec4f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">boardSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureDimensions</span><span class="p">(</span><span class="nx">inputBoard</span><span class="p">);</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">cell</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="nx">position</span><span class="p">.</span><span class="nx">xy</span><span class="p">);</span><span class="w"> </span><span class="c1">// 此片段的整数像素坐标。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">alive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureLoad</span><span class="p">(</span><span class="w"> </span><span class="nx">inputBoard</span><span class="p">,</span><span class="w"> </span><span class="nx">cell</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w">  </span><span class="c1">// 获取当前状态。</span>
<span class="w">                </span><span class="c1">// （请注意，状态在 r 颜色组件中。）</span>
<span class="w">        </span><span class="p">.</span>
<span class="w">        </span><span class="p">.</span><span class="w"> </span><span class="c1">// （计算 newAlive，细胞在下一代的状态，）</span>
<span class="w">        </span><span class="p">.</span>
<span class="w">    </span><span class="nx">textureStore</span><span class="p">(</span><span class="w"> </span><span class="nx">outputBoard</span><span class="p">,</span><span class="w"> </span><span class="nx">cell</span><span class="p">,</span><span class="w"> </span><span class="nx">vec4u</span><span class="p">(</span><span class="nx">newAlive</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">);</span><span class="w"> </span><span class="c1">// 存储新状态。</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">f32</span><span class="p">(</span><span class="nx">alive</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">vec4f</span><span class="p">(</span><span class="nx">c</span><span class="p">,</span><span class="nx">c</span><span class="p">,</span><span class="nx">c</span><span class="p">,</span><span class="mf">1</span><span class="p">);</span><span class="w"> </span><span class="c1">// 如果细胞现在是活的，则为白色，如果是死的，则为黑色。</span>
<span class="p">}</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>程序创建了两个纹理，texture1 和 texture2，并将 texture1 加载为棋盘的初始状态。以下是将 texture1 分配给着色器中的 inputBoard，将 texture2 分配给 outputBoard 的绑定组。它使用了上面显示的样本绑定组布局。
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nx">bindGroupA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="w">    </span><span class="c1">// 使用 texture1 进行输入，texture2 进行输出的绑定组。</span>
<span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="kt">bindGroupLayout</span><span class="p">,</span>
<span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="kt">texture1.createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="kt">texture2.createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
<p>第二个绑定组 bindGroupB 交换了纹理的角色。程序在第一次调用 draw() 时使用 bindGroupA，在第二次调用时使用 bindGroupB，在第三次调用时再次使用 bindGroupA，以此类推。</p>
<hr />
<p>生命游戏的第二个版本，<a href="../../../en/source/webgpu/life_2.html">webgpu/life_2.html</a>，采用了不同的方法。它使用两个格式为 "r8unorm" 的纹理来表示棋盘的当前状态和下一个状态。具有该格式的纹理可以用于着色器程序中的采样，因此可以使用 <code>textureSample()</code> 而不是 <code>textureLoad()</code> 从输入棋盘中读取值。并且 r8unorm 纹理可以作为渲染管线的输出目标。然后，片段着色器可以有两个输出，一个发送到画布，另一个发送到 r8unorm <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>。</p>
<p>要使片段着色器有第二个输出，管线描述符必须指定两个目标：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">pipelineDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="nx">fragment</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">module</span><span class="o">:</span><span class="w"> </span><span class="kt">shader</span><span class="p">,</span>
<span class="w">        </span><span class="nx">entryPoint</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;fragmentMain&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">targets</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="p">{</span><span class="w"> </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="kt">navigator.gpu.getPreferredCanvasFormat</span><span class="p">()</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="w"> </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;r8unorm&quot;</span><span class="p">}</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">...</span>
<span class="p">}</span>
</code></pre></div>
<p>然后渲染通道描述符使用输出纹理的视图作为第二个颜色附件：</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">renderPassDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">colorAttachments</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nx">clearValue</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">r</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">g</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="w"> </span><span class="p">},</span><span class="w"> </span>
<span class="w">            </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;clear&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="kt">context.getCurrentTexture</span><span class="p">().</span><span class="nx">createView</span><span class="p">()</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 第二个颜色附件是 r8unorm 纹理。</span>
<span class="w">            </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;load&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// （这里可以，因为内容完全被替换。）</span>
<span class="w">            </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="kt">outputTexture.createView</span><span class="p">()</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="p">};</span>
</code></pre></div>
<p>片段着色器的输出类型是一个包含两个输出值的结构体。有关全部细节，你当然应该查看两个示例生命程序的源代码。</p>
<hr />
<p>纹理是复杂的。我只涵盖了 <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr> 的部分内容。但我试图给你一个概述，包括你可能会需要的大部分信息。</p>
</div>
<div class="tabbed-block">
<p>The format of a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> specifies what kind of data is stored for each <abbr title="A pixel in a texture image.">texel</abbr>. The format specifies the number of color channels, the type of data, and in some cases how the data is interpreted. In the common 2D image format "rgba8unorm", there are four color channels ("r", "g", "b", and "a"). The data for a <abbr title="A pixel in a texture image.">texel</abbr> consists of 8 bits per color channel. And the value for a color channel is an unsigned integer ("u") in the range 0 to 255, which is divided by 255 to give a float value in the range 0.0 to 1.0 ("norm"). The format "bgra8unorm" is similar, but the order of the "r", "g", and "b" values is reversed. (One of these two formats, depending on platform, is the format for an <abbr title="HyperText Markup Language. A language that is used for specifying the content of web pages. An HTML document is made up of text, along with &quot;elements&quot; for adding other content, such as images, and for defining the structure of the document. Because of nesting of elements, the document can be represented by a tree-like data structure.">HTML</abbr> canvas; the function navigator.gpu.getPreferredCanvasFormat() returns the correct one for your platform. However, using the wrong format will not stop your program from working, since <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> does some format conversions automatically when reading and writing textures.)</p>
<p><abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> supports a large number of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> formats. There are formats with one color channel ("r"), two color channels ("rg"), and four color channels ("rgba"). The number of bits per color channel can be 8, 16, or 32. The data type can be float, unsigned integer, or signed integer. Some of the integer formats are normalized, but most are not. (There are also compressed <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> formats, which are not covered in this textbook.)</p>
<p>For example, the formats "r8uint", "r16uint", and "r32uint" are unsigned integer formats with one color channel and storing one 8-, 16-, or 32-bit unsigned integer per <abbr title="A pixel in a texture image.">texel</abbr>. For two 16-bit signed integers per <abbr title="A pixel in a texture image.">texel</abbr>, the format would be "rg16sint". The format "rgba32float" uses four 32-bit floating-point numbers per <abbr title="A pixel in a texture image.">texel</abbr>.</p>
<p>All textures can be passed into <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> programs as resources in bind groups, but only floating-point textures can be sampled using textureSample(). (This includes normalized integer formats.) However, the standard <abbr title="WebGPU 着色器语言，是编写 WebGPU 使用的着色器的编程语言。">WGSL</abbr> function textureLoad() can be used to read <abbr title="A pixel in a texture image.">texel</abbr> data from a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, and it works both for integer and for floating-point textures. This function treats the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> like an array: Instead of using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates to sample the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, you use integer <abbr title="A pixel in a texture image.">texel</abbr> coordinates to access the value at a specified <abbr title="A pixel in a texture image.">texel</abbr>. For example, to read from the <abbr title="A pixel in a texture image.">texel</abbr> in row 7, column 15 of a <code>texture_2d&lt;u32&gt;</code>, tex, you can use</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">texelValue</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec4u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureLoad</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="mf">7</span><span class="p">,</span><span class="mf">15</span><span class="p">),</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>The third parameter is the <abbr title="One of a series of reduced-size copies of a texture image, of decreasing width and height. Starting from the original image, each mipmap is obtained by dividing the width and height of the previous image by two (unless it is already 1). The final mipmap is a single pixel. Mipmaps are used for more efficient mapping of the texture image to a surface, when the image has to be shrunk to fit the surface.">mipmap</abbr> level, which is required but will usually be zero.</p>
<p>The return value from <code>textureLoad()</code> is always a 4-component <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, even when the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has only one or two color channels. The missing color channels are filled in with 0 for the "g" or "b" channel, and 1 for the "a" channel. (Note that the term "color" is used for integer textures, even though the values in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> probably don't represent colors. Floating-point textures can also store data other than colors.)</p>
<p>It is also possible for a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program to write <abbr title="A pixel in a texture image.">texel</abbr> data to a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, using the function <code>textureStore()</code>. However, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has to be passed into the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> as what is called a "storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>," and this only works for certain <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> formats. (There are lots of rules about what can be done with various <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> formats. The rules are summarized in a table of Texture Format Capabilities in Section 26.1 of the <abbr title="一种新的 JavaScript 图形 API，类似于 WebGL，但设计用于让网络程序访问现代 GPU 功能，如计算着色器。">WebGPU</abbr> specification.)</p>
<p>In a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr>, a storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has a type such as <code>texture_storage_2d&lt;r32uint,write&gt;</code>. The first type parameter, r32uint, is the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> format, and the second, write, specifies the access mode. (Currently, write is the only possibility.) The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is passed into the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> as a bind group resource, with resource type storageTexture, rather than <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. Here, for example, is a bind group layout for a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program that uses two r32uint textures, one for reading with <code>textureLoad()</code> and one for writing with <code>textureStore()</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">bindGroupLayout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroupLayout</span><span class="p">({</span>
<span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w">    </span><span class="c1">// for a texture_2d&lt;u32&gt; variable in the fragment shader</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span>
<span class="w">        </span><span class="nx">visibility</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUShaderStage.FRAGMENT</span><span class="p">,</span>
<span class="w">        </span><span class="nx">texture</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">sampleType</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;uint&quot;</span><span class="w">  </span><span class="c1">// Texel values are unsigned integers.</span>
<span class="w">            </span><span class="c1">// (Yes, it&#39;s called sampleType even though you can&#39;t sample it!)</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w">    </span><span class="c1">// for a texture_storage_2d&lt;r32uint,write&gt; in the fragment shader</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">        </span><span class="nx">visibility</span><span class="o">:</span><span class="w"> </span><span class="kt">GPUShaderStage.FRAGMENT</span><span class="p">,</span>
<span class="w">        </span><span class="nx">storageTexture</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;r32uint&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">access</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;write-only&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// This is the only possible value.</span>
<span class="w">            </span><span class="nx">viewDimension</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;2d&quot;</span><span class="w">    </span><span class="c1">// This is the default.</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
<p>Note that "storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>" just means a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> that has been passed to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> as a bind group resource of type textureStorage. The same <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> could be used as a regular <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> or as a storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, or both at different times.</p>
<p>The textureStore() function takes three parameters: the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the <abbr title="A pixel in a texture image.">texel</abbr> coordinates of the <abbr title="A pixel in a texture image.">texel</abbr> whose value is to be set, and the value. The value is always a 4-component <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, even if the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> has fewer than four color channels. The missing channels should be specified as 0 for the "g" or "b" channel and as 1 for the "a" channel. For example to set the single integer value at row 7, column 15 in a 2D r32uint storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to 17, you could use</p>
<div class="highlight"><pre><span></span><code><span class="nx">textureStore</span><span class="p">(</span><span class="w"> </span><span class="nx">tex</span><span class="p">,</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="mf">7</span><span class="p">,</span><span class="mf">15</span><span class="p">),</span><span class="w"> </span><span class="nx">vec4u</span><span class="p">(</span><span class="mf">17</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<hr />
<p>The sample program <a href="../../../en/source/webgpu/life_1.html">webgpu/life_1.html</a> implements John Conway's well-known Game of Life (see <a href="../../c6/s4/#645-计算示例">Subsection 6.4.5</a>). The game board is a 2D array of cells, where each cell can be alive or dead. In the program, the state of the board is stored as a 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> of type r32uint, with 0 representing a dead cell and 1 representing a living cell. The game board is displayed on a canvas, and each <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the canvas is a cell. So, the size of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is the same as the size of the canvas.</p>
<p>The action of the game involves computing a new "generation" of cells from the current generation. The program actually uses two textures: a regular <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> containing the current generation of the board and a storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> that is used to store the next generation as it is computed. The program does all its work in its draw() function. That function draws a square that completely covers the canvas, so that the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> is called once for each <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> on the canvas. The <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> uses textureLoad() to read the current state of the cell that it is processing. If the cell is alive, it returns white as the color of the fragment; if the cell is dead, it returns black. At the same time, the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> computes the state of the cell in the next generation, and it writes that state to the storage <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> using textureStore(). Between draws, the roles of the two textures are swapped, so that what was the next generation becomes the current generation.</p>
<p>Here is the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>, leaving out the part that computes the new state of the cell. It uses another new function, textureDimensions(), which gets the size of a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> in each of its dimensions. That value is required for the new state computation.</p>
<div class="highlight"><pre><span></span><code><span class="kd">@group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">inputBoard</span><span class="o">:</span><span class="w"> </span><span class="kt">texture_2d</span><span class="o">&lt;</span><span class="nx">u32</span><span class="o">&gt;</span><span class="p">;</span>
<span class="kd">@group</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="kd">@binding</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="nx">outputBoard</span><span class="o">:</span><span class="w"> </span><span class="kt">texture_storage_2d</span><span class="o">&lt;</span><span class="nx">r32uint</span><span class="p">,</span><span class="nx">write</span><span class="o">&gt;</span><span class="p">;</span>

<span class="kd">@fragment</span>
<span class="nx">fn</span><span class="w"> </span><span class="nx">fragmentMain</span><span class="p">(</span><span class="kd">@builtin</span><span class="p">(</span><span class="nx">position</span><span class="p">)</span><span class="w"> </span><span class="nx">position</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">vec4f</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kd">@location</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="w"> </span><span class="nx">vec4f</span><span class="w"> </span><span class="p">{</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">boardSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureDimensions</span><span class="p">(</span><span class="nx">inputBoard</span><span class="p">);</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">cell</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec2u</span><span class="p">(</span><span class="nx">position</span><span class="p">.</span><span class="nx">xy</span><span class="p">);</span><span class="w"> </span><span class="c1">// Integer pixel coords of this fragment.</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">alive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureLoad</span><span class="p">(</span><span class="w"> </span><span class="nx">inputBoard</span><span class="p">,</span><span class="w"> </span><span class="nx">cell</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w">  </span><span class="c1">// Get current state.</span>
<span class="w">                </span><span class="c1">// (Note that the state is in the r color component.)</span>
<span class="w">    </span><span class="p">.</span>
<span class="w">    </span><span class="p">.</span><span class="w"> </span><span class="c1">// (Compute newAlive, the state of the cell in the next generation,)</span>
<span class="w">    </span><span class="p">.</span>
<span class="nx">textureStore</span><span class="p">(</span><span class="w"> </span><span class="nx">outputBoard</span><span class="p">,</span><span class="w"> </span><span class="nx">cell</span><span class="p">,</span><span class="w"> </span><span class="nx">vec4u</span><span class="p">(</span><span class="nx">newAlive</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">0</span><span class="p">,</span><span class="mf">1</span><span class="p">)</span><span class="w"> </span><span class="p">);</span><span class="w"> </span><span class="c1">// Store new state.</span>
<span class="kd">let</span><span class="w"> </span><span class="nx">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">f32</span><span class="p">(</span><span class="nx">alive</span><span class="p">);</span>
<span class="k">return</span><span class="w"> </span><span class="nx">vec4f</span><span class="p">(</span><span class="nx">c</span><span class="p">,</span><span class="nx">c</span><span class="p">,</span><span class="nx">c</span><span class="p">,</span><span class="mf">1</span><span class="p">);</span><span class="w"> </span><span class="c1">// White if cell is now alive, black if it is dead.</span>
<span class="p">}</span>
</code></pre></div>
<p>The program creates two textures, texture1 and texture2, and loads texture1 with the initial state of the board. Here is the bind group that assigns texture1 to inputBoard in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> and texture2 to outputBoard. It uses the sample bind group layout shown above.</p>
<div class="highlight"><pre><span></span><code><span class="nx">bindGroupA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">device</span><span class="p">.</span><span class="nx">createBindGroup</span><span class="p">({</span>
<span class="w">    </span><span class="c1">// A bind group using texture1 for input and texture2 for output.</span>
<span class="nx">layout</span><span class="o">:</span><span class="w"> </span><span class="kt">bindGroupLayout</span><span class="p">,</span>
<span class="nx">entries</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="kt">texture1.createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nx">binding</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="p">,</span>
<span class="w">        </span><span class="nx">resource</span><span class="o">:</span><span class="w"> </span><span class="kt">texture2.createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
<span class="p">});</span>
</code></pre></div>
<p>A second bind group, bindGroupB, reverses the roles of the textures. The program uses bindGroupA the first time draw() is called, bindGroupB the second time, bindGroupA the third time, and so on.</p>
<hr />
<p>A second version of the Life program, <a href="../../../en/source/webgpu/life_2.html">webgpu/life_2.html</a>, uses a different approach. It uses two textures with format "r8unorm" to represent the current state and the next state of the board. A <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> with that format can be used for <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> in a <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program, so values can be read from the input board using <code>textureSample()</code> instead of <code>textureLoad()</code>. And a r8unorm <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can be an output target for a render <abbr title="A sequence of computational stages in a GPU that are applied to incoming data to produce some result. Some of the stages can be programmable shaders, such as vertex shaders, fragment shaders, and compute shaders. In a graphics rendering pipeline, the output is the colors of the pixels in an image.">pipeline</abbr>. The <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> can then have two outputs, one going to the canvas and one going to the r8unorm <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.</p>
<p>To have a second output from the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>, the <abbr title="A sequence of computational stages in a GPU that are applied to incoming data to produce some result. Some of the stages can be programmable shaders, such as vertex shaders, fragment shaders, and compute shaders. In a graphics rendering pipeline, the output is the colors of the pixels in an image.">pipeline</abbr> descriptor must specify two targets:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">pipelineDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="p">...</span>
<span class="w">    </span><span class="nx">fragment</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">module</span><span class="o">:</span><span class="w"> </span><span class="kt">shader</span><span class="p">,</span>
<span class="w">    </span><span class="nx">entryPoint</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;fragmentMain&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nx">targets</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="p">{</span><span class="w"> </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="kt">navigator.gpu.getPreferredCanvasFormat</span><span class="p">()</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span><span class="w"> </span><span class="nx">format</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;r8unorm&quot;</span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">...</span>
</code></pre></div>
<p>Then the render pass descriptor uses a view of the output <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> as the second color attachment:</p>
<div class="highlight"><pre><span></span><code><span class="kd">let</span><span class="w"> </span><span class="nx">renderPassDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="nx">colorAttachments</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nx">clearValue</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">r</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">g</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="o">:</span><span class="w"> </span><span class="kt">1</span><span class="w"> </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;clear&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">        </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="kt">context.getCurrentTexture</span><span class="p">().</span><span class="nx">createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w">  </span><span class="c1">// The second color attachment is a r8unorm texture.</span>
<span class="w">        </span><span class="nx">loadOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;load&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// (OK here since contents are entirely replaced.)</span>
<span class="w">        </span><span class="nx">storeOp</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;store&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nx">view</span><span class="o">:</span><span class="w"> </span><span class="kt">outputTexture.createView</span><span class="p">()</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
<span class="p">};</span>
</code></pre></div>
<p>The output type for the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> is a struct that contains the two output values. For full details, you should, of course, look at the source code for the two sample Life programs.</p>
<hr />
<p>Textures are complex. I have only covered parts of the <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr>. But I have tried to give you an overview that includes most of the information that you are likely to need.</p>
</div>
</div>
</div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2024年7月6日</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2024年5月26日</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "content.tabs.link", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.top", "toc.follow", "content.tooltips"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>