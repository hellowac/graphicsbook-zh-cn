
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="计算机图形学概论(graphicsbook)">
      
      
      
        <link rel="canonical" href="https://hellowac.github.io/graphicsbook-zh-cn/cn/c7/s3/">
      
      
        <link rel="prev" href="../s2/">
      
      
        <link rel="next" href="../s4/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.28">
    
    
      
        <title>7.3 纹理 - 计算机图形学概论</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 12a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M6 13h8l-3.5 3.5 1.42 1.42L17.84 12l-5.92-5.92L10.5 7.5 14 11H6v2Z"/></svg>');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="default" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#73-纹理" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="计算机图形学概论" class="md-header__button md-logo" aria-label="计算机图形学概论" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            计算机图形学概论
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              7.3 纹理
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="选择当前语言">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/graphicsbook-zh-cn/en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/graphicsbook-zh-cn/cn/" hreflang="cn" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/hellowac/graphicsbook-zh-cn" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    graphicsbook
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../" class="md-tabs__link">
        
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../preface/" class="md-tabs__link">
        
  
    
  
  前言

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c1/" class="md-tabs__link">
          
  
    
  
  1.简介

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c2/" class="md-tabs__link">
          
  
    
  
  2.二维图形

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c3/" class="md-tabs__link">
          
  
    
  
  3.几何

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c4/" class="md-tabs__link">
          
  
    
  
  4.灯光和材质

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c5/" class="md-tabs__link">
          
  
    
  
  5.three.js

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c6/" class="md-tabs__link">
          
  
    
  
  6.WebGL

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  7.WebGL 3D

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c8/" class="md-tabs__link">
          
  
    
  
  8.高阶3D

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../c9/" class="md-tabs__link">
          
  
    
  
  9.WEBGPU

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a1/" class="md-tabs__link">
          
  
    
  
  附录A

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a2/" class="md-tabs__link">
          
  
    
  
  附录B

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../a3/" class="md-tabs__link">
          
  
    
  
  附录C

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../source/" class="md-tabs__link">
          
  
    
  
  附录D

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../glossary/" class="md-tabs__link">
          
  
    
  
  术语表

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  关于

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="计算机图形学概论" class="md-nav__button md-logo" aria-label="计算机图形学概论" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    计算机图形学概论
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/hellowac/graphicsbook-zh-cn" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    graphicsbook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preface/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    1.简介
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            1.简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 1 节 绘画与绘图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 2 节：三维(3D)图形的要素
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c1/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 3 节：硬件与软件
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    2.二维图形
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            2.二维图形
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第1节: 像素、坐标和颜色
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第2节: 形状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第3节: 变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第4节: 分层建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第5节: Java 绘制2D
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第6节: HTML Canvas图形
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c2/s7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第7节: SVG：一种场景描述语言
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    3.几何
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            3.几何
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 OpenGL 1.1 中的形状和颜色
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 3D 坐标和变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 投影与观看
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 多边形网格和 glDrawArrays
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.5 部分线性代数基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c3/s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.6 使用 GLUT 和 JOGL
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c4/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    4.灯光和材质
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            4.灯光和材质
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 照明简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 OpenGL 1.1 中的光和材质
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 图像纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c4/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 灯光、相机、动作
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c5/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    5.three.js
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            5.three.js
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 Three.js 基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 构建对象
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c5/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 其他功能
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c6/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    6.WebGL
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_8" id="__nav_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            6.WebGL
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 可编程流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 第一个例子
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 GLSL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 图像纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c6/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 实现 2D 变换
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    7.WebGL 3D
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_9" id="__nav_9_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            7.WebGL 3D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 3D变换
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.2 照明和材质
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    7.3 纹理
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    7.3 纹理
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#731-使用-glmatrix-进行纹理变换" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.1 使用 glMatrix 进行纹理变换
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#732-生成纹理坐标" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.2 生成纹理坐标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#733-程序纹理" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.3 程序纹理
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#734-凹凸贴图" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.4 凹凸贴图
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#735-环境映射" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.5 环境映射
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.4 帧缓冲区
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.5 WebGL 扩展
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c8/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    8.高阶3D
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_10" id="__nav_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            8.高阶3D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c8/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.1 光线追踪
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c8/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8.2 路径追踪
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../c9/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    9.WEBGPU
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            9.WEBGPU
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.1 WebGPU 基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.2 实例和索引
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.3 WGSL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.4 WebGPU 中的 3D 图形
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.5 纹理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.6 计算着色器
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../c9/s7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9.7 细节
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录A
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_12" id="__nav_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            附录A
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.1 Java 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.2 C 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.3 JavaScript 编程语言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a1/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A.4 JavaScript Promise 和异步函数
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录B
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_13" id="__nav_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            附录B
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.1 节 Blender 基础知识
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.2 节 Blender 建模
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.3 节 Blender 动画
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a2/s4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    B.4 节 有关光和材料的更多信息
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../a3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录C
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14" id="__nav_14_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            附录C
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../a3/s1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C.1 节 Gimp：2D 绘画程序
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../source/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    附录D
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            附录D
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_16" >
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    术语表
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            术语表
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    术语表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#731-使用-glmatrix-进行纹理变换" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.1 使用 glMatrix 进行纹理变换
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#732-生成纹理坐标" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.2 生成纹理坐标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#733-程序纹理" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.3 程序纹理
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#734-凹凸贴图" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.4 凹凸贴图
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#735-环境映射" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.5 环境映射
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="73-纹理">7.3 <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr><a class="headerlink" href="#73-纹理" title="Permanent link">&para;</a></h1>
<p><strong>Textures</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">中文</label><label for="__tabbed_1_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr> 中大部分与纹理相关的功能在 <a href="../../c6/s4/">第6.4节</a> 中已经介绍过了。在这一部分，我们将看一些使用纹理的示例和技术。</p>
</div>
<div class="tabbed-block">
<p>Most of the <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> <abbr title="Application Programming Interface. A collection of related classes, functions, constants, etc., for performing some task. An API is an &quot;interface&quot; in the sense that it can be used without understanding how its functionality is actually implemented.">API</abbr> for working with textures was already covered in <a href="../../c6/s4/">Section 6.4</a>. In this section, we look at several examples and techniques for using textures.</p>
</div>
</div>
</div>
<h2 id="731-使用-glmatrix-进行纹理变换">7.3.1 使用 <abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr> 进行纹理变换<a class="headerlink" href="#731-使用-glmatrix-进行纹理变换" title="Permanent link">&para;</a></h2>
<p><strong>Texture Transforms with <abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr></strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">中文</label><label for="__tabbed_2_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>在 <a href="../../c4/s3/#434-纹理变换">4.3.4小节</a> 中，我们看到了如何在 <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 中应用纹理变换。<abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> 维护了一个纹理变换矩阵，可以操纵它来在采样纹理之前对纹理坐标进行缩放、旋转和平移。在 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中以相同的方式编程这些操作也很容易。我们需要在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端计算纹理变换矩阵。然后，将变换矩阵发送到着色器程序中的 uniform 矩阵变量，在那里它可以被应用到纹理坐标上。请注意，只要纹理变换是仿射的，它就可以在顶点着色器中应用，即使纹理是在片段着色器中采样的。也就是说，在顶点着色器中进行变换并在片段着色器中插值变换后的纹理坐标，将得到与在片段着色器中插值原始纹理坐标并应用变换到插值坐标相同的结果。</p>
<p>由于我们使用 <em><abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr></em> 进行 3D 中的坐标变换，使用它进行纹理变换也是有意义的。如果我们使用 2D <abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr>，我们可以使用 <em><abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr></em> 中的 <strong><em>mat3</em></strong> 类在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端实现缩放、旋转和平移。我们需要的函数有：</p>
<ul>
<li><code>mat3.create()</code> — 返回一个新的 3x3 <abbr title="数字的矩形数组。矩阵可以表示为二维数组，数字按行和列排列。一个N×N矩阵表示从N维空间到自身的线性变换。">矩阵</abbr>（表示为长度为 9 的数组）。新矩阵是单位矩阵。</li>
<li><code>mat3.identity(A)</code> — 将 A 设置为单位矩阵，其中 <em>A</em> 是一个已经存在的 <strong><em>mat3</em></strong>。</li>
<li><code>mat3.translate(A,B,[dx,dy])</code> — 将矩阵 <em>B</em> 乘以表示 (dx,dy) 平移的矩阵，并将结果矩阵设置为 <em>A</em>。<em>A</em> 和 <em>B</em> 必须已经存在。</li>
<li><code>mat3.scale(A,B,[sx,sy])</code> — 将 <em>B</em> 乘以表示 (sx,sy) 缩放的矩阵，并将结果矩阵设置为 A。</li>
<li><code>mat3.rotate(A,B,angle)</code> — 将 <em>B</em> 乘以表示绕原点旋转 angle 弧度的矩阵，并将结果矩阵设置为 A。</li>
</ul>
<p>对于实现纹理变换，这些函数中的参数 A 和 B 将是纹理变换矩阵。例如，要将纹理坐标缩放 2 倍，我们可能会使用以下代码：</p>
<div class="highlight"><pre><span></span><code><span class="kd">var</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">mat3</span><span class="p">.</span><span class="nx">create</span><span class="p">();</span>
<span class="nx">mat3</span><span class="p">.</span><span class="nx">scale</span><span class="p">(</span><span class="w"> </span><span class="nx">textureTransform</span><span class="p">,</span><span class="w"> </span><span class="nx">textureTransform</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">]</span><span class="w"> </span><span class="p">);</span>
<span class="nx">gl</span><span class="p">.</span><span class="nx">uniformMatrix3fv</span><span class="p">(</span><span class="w"> </span><span class="nx">u_textureTransform</span><span class="p">,</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>最后一行假设 <em>u_textureTransform</em> 是着色器程序中类型为 <em>mat3</em> 的 uniform 变量的位置。（并请记住，将纹理坐标缩放 2 倍将使其应用到的表面的纹理尺寸 <strong>缩小</strong>。）</p>
<p>示例 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 程序 <a href="../../../en/source/webgl/texture-transform.html">webgl/<abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>-transform.html</a> 使用纹理变换来动画化纹理。在这个程序中，纹理坐标作为类型为 <em>vec2</em> 的属性 <em>a_texCoords</em> 输入到顶点着色器，并且纹理变换是一个名为 <em>textureTransform</em> 的 uniform 变量，类型为 <em>mat3</em>。在顶点着色器中使用 <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> 命令计算变换后的纹理坐标：</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="nx">a_texCoords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="nx">v_texCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texcoords</span><span class="p">.</span><span class="nx">xy</span><span class="p">;</span>
</code></pre></div>
<p>阅读源代码，了解所有这些是如何在一个完整程序的上下文中使用的。</p>
</div>
<div class="tabbed-block">
<p>In <a href="../../c4/s3/#434-纹理变换">Subsection 4.3.4</a>, we saw how to apply a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation in <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr>. <abbr title="A family of computer graphics APIs that is implemented in many graphics hardware devices. There are several versions of the API, and there are implementations, or &quot;bindings&quot; for several different programming languages. Versions of OpenGL for embedded systems such as mobile phones are known as OpenGL ES. WebGL is a version for use on Web pages. OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly associated with 3D.">OpenGL</abbr> maintains a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transform <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> that can be manipulated to apply <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr>, <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr>, and <abbr title="A geometric transform that adds a given translation amount to each coordinate of a point. Translation is used to move objects without changing their size or orientation.">translation</abbr> to <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates before they are used to sample a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. It is easy to program the same operations in <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>. We need to compute the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transform <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side. The transform <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> is then sent to a uniform <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> variable in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program, where it can be applied to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. Note that as long as the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation is affine, it can be applied in the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr>, even though the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is sampled in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>. That is, doing the transformation in the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> and interpolating the transformed <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates will give the same result as interpolating the original <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates and applying the transformation to the interpolated coordinates in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>.</p>
<p>Since we are using <em><abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr></em> for coordinate transformation in 3D, it makes sense to use it for <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transforms as well. If we use 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, we can implement <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr>, <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr>, and <abbr title="A geometric transform that adds a given translation amount to each coordinate of a point. Translation is used to move objects without changing their size or orientation.">translation</abbr> on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side using the <strong><em>mat3</em></strong> class from <em><abbr title="一个用于二维和三维向量和矩阵数学的开源JavaScript库。">glMatrix</abbr></em>. The functions that we need are</p>
<ul>
<li><code>mat3.create()</code> — Returns a new 3-by-3 <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> (represented as an array of length 9). The new <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> is the <abbr title="The n-by-n identity matrix is an n-by-n matrix which has ones on the diagonal and zeros elsewhere. Multiplication of any matrix B by the identity matrix, in either order, leaves B unchanged. Multiplication of an n-dimensional vector by the n-by-n identity matrix leaves the vector unchanged; that is, the identity matrix is the matrix for the identity transformation.">identity matrix</abbr>.</li>
<li><code>mat3.identity(A)</code> — Sets A to be the <abbr title="The n-by-n identity matrix is an n-by-n matrix which has ones on the diagonal and zeros elsewhere. Multiplication of any matrix B by the identity matrix, in either order, leaves B unchanged. Multiplication of an n-dimensional vector by the n-by-n identity matrix leaves the vector unchanged; that is, the identity matrix is the matrix for the identity transformation.">identity matrix</abbr>, where <em>A</em> is an already-existing <strong><em>mat3</em></strong>.</li>
<li><code>mat3.translate(A,B,[dx,dy])</code> — Multiplies the <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> <em>B</em> by a <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> representing <abbr title="A geometric transform that adds a given translation amount to each coordinate of a point. Translation is used to move objects without changing their size or orientation.">translation</abbr> by <em>(dx,dy)</em>, and sets <em>A</em> to be the resulting <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>. <em>A</em> and <em>B</em> must already exist.</li>
<li><code>mat3.scale(A,B,[sx,sy])</code> — Multiplies <em>B</em> by a <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> representing <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr> by <em>(sx,sy)</em>, and sets A to be the resulting <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>.</li>
<li><code>mat3.rotate(A,B,angle)</code> — Multiplies <em>B</em> by a <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr> representing <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr> by angle radians about the origin, and sets A to be the resulting <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>.</li>
</ul>
<p>For implementing <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformations, the parameters A and B in these functions will be the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transform <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>. For example, to apply a <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr> by a factor of 2 to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, we might use the code:</p>
<div class="highlight"><pre><span></span><code><span class="kd">var</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">mat3</span><span class="p">.</span><span class="nx">create</span><span class="p">();</span>
<span class="nx">mat3</span><span class="p">.</span><span class="nx">scale</span><span class="p">(</span><span class="w"> </span><span class="nx">textureTransform</span><span class="p">,</span><span class="w"> </span><span class="nx">textureTransform</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="mf">2</span><span class="p">]</span><span class="w"> </span><span class="p">);</span>
<span class="nx">gl</span><span class="p">.</span><span class="nx">uniformMatrix3fv</span><span class="p">(</span><span class="w"> </span><span class="nx">u_textureTransform</span><span class="p">,</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>The last line assumes that <em>u_textureTransform</em> is the location of a <abbr title="Variables that represent input to a shader program in a programmable graphics pipeline. A uniform variable has the same value at every vertex and at every pixel of a primitive.">uniform variable</abbr> of type <em>mat3</em> in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program. (And remember that <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates by a factor of 2 will <strong>shrink</strong> the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> on the surfaces to which it is applied.)</p>
<p>The sample <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> program <a href="../../../en/source/webgl/texture-transform.html">webgl/<abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>-transform.html</a> uses <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformations to animate textures. In the program, <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are input into the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> as an <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> named <em>a_texCoords</em> of type <em>vec2</em>, and the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation is a <abbr title="Variables that represent input to a shader program in a programmable graphics pipeline. A uniform variable has the same value at every vertex and at every pixel of a primitive.">uniform variable</abbr> named <em>textureTransform</em> of type <em>mat3</em>. The transformed <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are computed in the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> with the <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> commands</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="nx">a_texCoords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="nx">v_texCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texcoords</span><span class="p">.</span><span class="nx">xy</span><span class="p">;</span>
</code></pre></div>
<p>Read the source code to see how all this is used in the context of a complete program.</p>
</div>
</div>
</div>
<h2 id="732-生成纹理坐标">7.3.2 生成纹理坐标<a class="headerlink" href="#732-生成纹理坐标" title="Permanent link">&para;</a></h2>
<p><strong>Generated Texture Coordinates</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">中文</label><label for="__tabbed_3_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>纹理坐标通常作为属性变量提供给着色器程序。但是，当纹理坐标不可用时，可以在着色器程序中生成它们。虽然使用为正在渲染的对象定制的纹理坐标的结果通常看起来更好，但在某些情况下，使用生成的纹理坐标也是可以接受的。</p>
<p>生成的纹理坐标应该从正在渲染的对象的对象坐标计算得出。也就是说，它们从原始顶点坐标计算得出，即在应用任何变换之前。然后，当对象被变换时，纹理也会随着对象一起变换，看起来就好像纹理附着在对象上。纹理坐标可以是对象坐标的几乎任何函数。如果使用仿射函数，通常也是如此，那么可以在顶点着色器中计算纹理坐标。否则，需要将对象坐标作为变化变量发送到片段着色器并在其中进行计算。</p>
<p>生成纹理坐标的最简单想法就是简单地使用对象坐标系中的 x 和 y 坐标作为纹理坐标。如果顶点坐标作为属性变量 <em>a_coords</em> 的值给出，那就意味着使用 <em>a_coords.xy</em> 作为纹理坐标。这种映射的效果是从正 z 轴方向将纹理投影到表面上，垂直于 xy 平面。这种映射对于面向正 z 方向的多边形效果不错，但对于与 xy 平面对齐的多边形则效果不佳。下面是在立方体上的映射效果：</p>
<p><a class="glightbox" href="../../../en/c7/generated-texcoords-xy.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/generated-texcoords-xy.png" /></a></p>
<p>纹理在立方体的正面上投影得很好。它在立方体的背面（在图像中不可见）上的效果也不错，除了是镜像反转的。在与 xy 平面完全对齐的另外四个面上，你只会得到来自纹理图像边框沿线的像素的颜色线。（在这个例子中，一个纹理图像的副本完全填满了立方体的正面。这不是自动发生的；你可能需要一个纹理变换来使纹理图像适应表面。）</p>
<p>当然，我们可以用其他方向投影来映射立方体的其他面。但是如何决定使用哪个方向呢？假设我们想沿着坐标轴的方向投影。我们至少想从表面面向的方向投影。表面法线向量告诉我们那个方向。我们应该在法线向量幅度最大的方向投影。例如，如果法线向量是 (0.12, 0.85, 0.51)，那么我们应该从正 y 轴方向投影。而法线向量等于 (−0.4, 0.56, −0.72) 会告诉我们从负 z 轴方向投影。这种“立方体”生成的纹理坐标对立方体来说是完美的，对大多数对象看起来也相当不错，只是可能在投影方向变化的接缝处会有问题。这里，例如，技术被应用到一个茶壶上：</p>
<p><a class="glightbox" href="../../../en/c7/cubical-texture-coords-teapot.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cubical-texture-coords-teapot.png" /></a></p>
<p>当使用平面着色时，所有多边形的法线都指向同一方向，可以在顶点着色器中进行计算。使用平滑着色时，多边形的不同顶点的法线可能指向不同的方向。如果在不同顶点从不同方向投影纹理坐标并对结果进行插值，结果可能是一团糟。因此，在片段着色器中进行计算更安全。假设插值后的法线向量和对象坐标以名为 <em>v_normal</em> 和 <em>v_objCoords</em> 的变化变量提供给片段着色器。然后可以使用以下代码生成“立方体”<abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr>：</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="p">))</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
<span class="w">                                </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">))</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 沿 x 轴投影</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">yz</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">zy</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">))</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
<span class="w">                                </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="p">))</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 沿 z 轴投影</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">xy</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">yx</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 沿 y 轴投影</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">zx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">xz</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>例如，沿 x 轴投影时，使用 <em>v_objCoords</em> 的 y 和 z 坐标作为纹理坐标。根据 x 的正方向或负方向投影，坐标被计算为 <em>v_objCoords.yz</em> 或 <em>v_objCoords.zy</em>。选择这两个坐标的顺序是为了使纹理图像直接投影到表面上，而不是镜像反转。</p>
<p>你可以使用以下演示尝试生成纹理。演示显示了使用上述立方体生成纹理坐标的各种纹理和对象。你还可以尝试只将纹理坐标投影到 xy 或 zx 平面上，以及将纹理图像环绕圆柱体一次的圆柱投影。最后一个选项是使用眼睛坐标系中的 x 和 y 坐标作为纹理坐标。这个选项将纹理固定在屏幕上而不是对象上，所以纹理不会随着对象旋转。效果很有趣，但可能不是很有用。</p>
<p><iframe src="../../../en/demos/c7/generated-texcoords.html" width="680" height="480"></iframe></p>
</div>
<div class="tabbed-block">
<p>Texture coordinates are typically provided to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program as an <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variable. However, when <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are not available, it is possible to generate them in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program. While the results will not usually look as good as using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates that are customized for the object that is being rendered, they can be acceptable in some cases.</p>
<p>Generated <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates should usually be computed from the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> of the object that is being rendered. That is, they are computed from the original <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> coordinates, before any transformation has been applied. Then, when the object is transformed, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> will be transformed along with the object so that it will look like the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is attached to the object. The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates could be almost any function of the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr>. If an affine function is used, as is usually the case, then the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates can be computed in the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr>. Otherwise, you need to send the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> to the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in a <abbr title="A variable that is used to communicate values from the vertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline. A varying variable is assigned a value in the vertex shader. The value of the variable in the fragment shader for a pixel in the primitive is obtained by interpolating the values from the vertices of the primitive. (In newer versions of GLSL, which support additional shader stages, the term &quot;varying variable&quot; is replaced by the more general terms &quot;in variable&quot; and &quot;out variable,&quot; which refer to variables that are used for input to or output from a shader.)">varying variable</abbr> and do the computation there.</p>
<p>The simplest idea for generated <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates is simply to use the x and y coordinates from the object <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> as the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. If the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> coordinates are given as the value of the <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variable <em>a_coords</em>, that would mean using <em>a_coords.xy</em> as <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. This has the effect of projecting the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> onto the surface from the direction of the positive z-axis, perpendicular to the <em>xy</em>-plane. The mapping works OK for a <abbr title="A multi-sided shape lying in a plane and specified by a list of points, called its vertices, and made up of the line segments from each point in the list to the next point in the list, plus a line segment from the last point in the list to the first point. All the points are required to lie in the same plane. Sometimes the term &quot;polygon&quot; includes the interior of the shape as well as its boundary.">polygon</abbr> that is facing, more-or-less, in the direction of positive z, but it doesn't give good results for polygons that are edge-on to the xy-plane. Here's what the mapping looks like on a cube:</p>
<p><a class="glightbox" href="../../../en/c7/generated-texcoords-xy.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/generated-texcoords-xy.png" /></a></p>
<p>The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> projects nicely onto the <abbr title="One of the two sides of a polygon in 3D. A polygon has two sides. One is taken to be the front face, and the other is the back face. In OpenGL, the difference is determined by the order in which the vertices of the polygon are enumerated. The default is that, seen from the front, the vertices are enumerated in counterclockwise order around the polygon.">front face</abbr> of the cube. It also works OK on the <abbr title="One of the two sides of a polygon in 3D. A polygon has two sides. One is taken to be the front face, and the other is the back face. In OpenGL, the difference is determined by the order in which the vertices of the polygon are enumerated. The default is that, seen from the back, the vertices are enumerated in clockwise order around the polygon.">back face</abbr> of the cube (not visible in the image), except that it is mirror-reversed. On the other four faces, which are exactly edge-on to the xy-plane, you just get lines of color that come from <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr> along the border of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image. (In this example, one copy of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image exactly fills the <abbr title="One of the two sides of a polygon in 3D. A polygon has two sides. One is taken to be the front face, and the other is the back face. In OpenGL, the difference is determined by the order in which the vertices of the polygon are enumerated. The default is that, seen from the front, the vertices are enumerated in counterclockwise order around the polygon.">front face</abbr> of the cube. That doesn't happen automatically; you might need a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transform to adapt the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image to the surface.)</p>
<p>Of course, we could project in other directions to map the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to other faces of the cube. But how to decide which direction to use? Let's say that we want to project along the direction of one of the coordinate axes. We want to project, approximately at least, from the direction that the surface is facing. The <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to the surface tells us that direction. We should project in the direction where the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> has its greatest magnitude. For example, if the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> is (0.12, 0.85, 0.51), then we should project from the direction of the positive y-axis. And a <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> equal to (−0.4, 0.56, −0.72) would tell us to project from the direction of the negative z-axis. This resulting "cubical" generated <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are perfect for a cube, and it looks pretty good on most objects, except that there can be a seam where the direction of <abbr title="A transformation that maps coordinates in 3D to coordinates in 2D. Projection is used to convert a three-dimensional scene into a two-dimensional image.">projection</abbr> changes. Here, for example, the technique is applied to a teapot:</p>
<p><a class="glightbox" href="../../../en/c7/cubical-texture-coords-teapot.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cubical-texture-coords-teapot.png" /></a></p>
<p>When using <abbr title="A lighting computation for the faces of a polygon or polygonal mesh that uses the same normal vector at each point in the polygon, giving the polygon a flat or faceted appearance.">flat shading</abbr>, so that all of the normals to a <abbr title="A multi-sided shape lying in a plane and specified by a list of points, called its vertices, and made up of the line segments from each point in the list to the next point in the list, plus a line segment from the last point in the list to the first point. All the points are required to lie in the same plane. Sometimes the term &quot;polygon&quot; includes the interior of the shape as well as its boundary.">polygon</abbr> point in the same direction, the computation can be done in the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr>. With <abbr title="A lighting computation for the faces of a polygon or polygonal mesh that uses a different normal vector at each vertex of the polygon. When two polygons share a vertex, both polygons use the same normal vector for that vertex, resulting in a smooth appearance at that vertex. Smooth shading is appropriate when a polygonal mesh is used as an approximation for a smooth surface.">smooth shading</abbr>, normals at different vertices of a <abbr title="A multi-sided shape lying in a plane and specified by a list of points, called its vertices, and made up of the line segments from each point in the list to the next point in the list, plus a line segment from the last point in the list to the first point. All the points are required to lie in the same plane. Sometimes the term &quot;polygon&quot; includes the interior of the shape as well as its boundary.">polygon</abbr> can point in different directions. If you project <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates from different directions at different vertices and interpolate the results, the result is likely to be a mess. So, doing the computation in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> is safer. Suppose that the interpolated normal vectors and <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> are provided to the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in varying variables named <em>v_normal</em> and <em>v_objCoords</em>. Then the following code can be used to generate "cubical" <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates:</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="p">))</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
<span class="w">                                </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">))</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// project along the x-axis</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">yz</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">zy</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">x</span><span class="p">))</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
<span class="w">                                </span><span class="p">(</span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nx">abs</span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="p">))</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// project along the z-axis</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">z</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">xy</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">yx</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// project along the y-axis</span>
<span class="w">    </span><span class="nx">texcoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v_normal</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">zx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">.</span><span class="nx">xz</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>When projecting along the <em>x-axis</em>, for example, the y and z coordinates from <em>v_objCoords</em> are used as <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. The coordinates are computed as either <em>v_objCoords.yz</em> or <em>v_objCoords.zy</em>, depending on whether the <abbr title="A transformation that maps coordinates in 3D to coordinates in 2D. Projection is used to convert a three-dimensional scene into a two-dimensional image.">projection</abbr> is from the positive or the negative direction of x. The order of the two coordinates is chosen so that a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image will be <abbr title="A transformation that maps coordinates in 3D to coordinates in 2D. Projection is used to convert a three-dimensional scene into a two-dimensional image.">projected</abbr> directly onto the surface, rather than mirror-reversed.</p>
<p>You can experiment with generated textures using the following demo. The demo shows a variety of textures and objects using cubical generated <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, as discussed above. You can also try <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates <abbr title="A transformation that maps coordinates in 3D to coordinates in 2D. Projection is used to convert a three-dimensional scene into a two-dimensional image.">projected</abbr> just onto the xy or zx plane, as well as a cylindrical <abbr title="A transformation that maps coordinates in 3D to coordinates in 2D. Projection is used to convert a three-dimensional scene into a two-dimensional image.">projection</abbr> that wraps a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image once around a cylinder. A final option is to use the x and y coordinates from the eye <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> as <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. That option fixes the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> on the screen rather than on the object, so the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> doesn't rotate with the object. The effect is interesting, but probably not very useful.</p>
<p><iframe src="../../../en/demos/c7/generated-texcoords.html" width="680" height="480"></iframe></p>
</div>
</div>
</div>
<h2 id="733-程序纹理">7.3.3 程序纹理<a class="headerlink" href="#733-程序纹理" title="Permanent link">&para;</a></h2>
<p><strong>Procedural Textures</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">中文</label><label for="__tabbed_4_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>到目前为止，我们的所有纹理都是图像纹理。在图像纹理中，颜色是通过基于一对纹理坐标采样图像来计算的。图像本质上定义了一个函数，它将纹理坐标作为输入，并返回作为输出的颜色。然而，除了在图像中查找值之外，还有定义此类函数的其他方式。<strong><abbr title="在给定的纹理坐标集合上，其值作为纹理坐标的数学函数来计算的纹理，与通过采样图像获得值的图像纹理相对。">过程纹理</abbr></strong>是由一个函数定义的，其值是计算出来的，而不是查找出来的。也就是说，纹理坐标被用作代码段的输入，其输出是纹理的相应颜色值。</p>
<p>在 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中，过程纹理可以在片段着色器中定义。这个想法很简单：取一个表示一组纹理坐标的 <em>vec2</em>。然后，不是使用 <em>sampler2D</em> 来查找颜色，而是使用 <em>vec2</em> 作为一些数学计算的输入，该计算计算出一个表示颜色的 vec4。理论上任何计算都可以使用，只要 <em>vec4</em> 的分量在 0.0 到 1.0 的范围内。</p>
<p>我们甚至可以将这个想法扩展到 3D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>。2D 纹理使用 <em>vec2</em> 作为纹理坐标。对于 3D <abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr>，我们使用 <em>vec3</em>。与将点映射到平面上的颜色不同，3D 纹理将空间中的点映射到颜色。可以有类似于图像纹理的 3D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>。也就是说，为 3D 网格中的每个点存储一个颜色值，并通过在网格中查找颜色来采样纹理。然而，一个 3D 颜色网格占用很多内存。另一方面，3D 过程纹理不使用内存资源，并且比 2D 过程纹理多使用很少的计算资源。</p>
<p>那么，可以用过程纹理做什么呢？实际上，可以做很多事情。与过程纹理相关的理论和实践非常丰富。我们将看一些可能性。这里有一个使用四种不同过程纹理的环面。这些图像来自本小节末尾演示的示例：</p>
<p><a class="glightbox" href="../../../en/c7/procedural-textures-torus.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/procedural-textures-torus.png" /></a></p>
<p>左边的环面使用了一个表示棋盘格图案的 2D <abbr title="在给定的纹理坐标集合上，其值作为纹理坐标的数学函数来计算的纹理，与通过采样图像获得值的图像纹理相对。">过程纹理</abbr>。2D 纹理坐标通常作为着色器程序中顶点属性变量的值提供。棋盘格图案是规则的等大小彩色正方形网格，但与任何 2D 纹理一样，当图案映射到环面的曲面时，图案会被拉伸和扭曲。给定在变化变量 <em>v_texCoords</em> 中的纹理坐标，可以在片段着色器中按如下方式计算棋盘格纹理的颜色值：</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec4</span><span class="w"> </span><span class="nx">color</span><span class="p">;</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">floor</span><span class="p">(</span><span class="nx">v_texCoords</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">scale</span><span class="p">);</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">floor</span><span class="p">(</span><span class="nx">v_texCoords</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">scale</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">mod</span><span class="p">(</span><span class="nx">a</span><span class="o">+</span><span class="nx">b</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// a+b 是奇数</span>
<span class="w">    </span><span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"> </span><span class="c1">// 粉红色</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// a+b 是偶数</span>
<span class="w">    </span><span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="w"> </span><span class="mf">0.6</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"> </span><span class="c1">// 浅蓝色</span>
<span class="p">}</span>
</code></pre></div>
<p>第二行和第三行中的 <em>scale</em> 表示用于适应被纹理化对象大小的纹理变换。（环面的纹理坐标范围从 0 到 1；没有缩放，棋盘格图案中只有一个正方形会被映射到环面。在图片中的环面，<em>scale</em> 是 8。）floor 函数计算小于或等于其参数的最大整数，所以 a 和 b 是整数。<em>mod(a+b,2.0)</em> 的值要么是 0.0，要么是 1.0，所以第四行中的测试检查 <em>a+b</em> 是偶数还是奇数。这里的想法是，当 a 或 b 增加或减少 1 时，<em>a+b</em> 将从偶数变为奇数，或从奇数变为偶数；这确保了图案中邻近的正方形将被不同颜色。</p>
<p>插图中的第二个环面使用了 3D 棋盘格图案。3D 棋盘格由在所有三个方向上交替颜色的立方体网格组成。对于立方体的 3D <abbr title="指应用于纹理图像的二维坐标系统，或用于1D和3D纹理的类似坐标系统。纹理坐标通常在垂直和水平方向上都从0到1变化，其中(0,0)位于图像的左下角。该术语还指赋予表面的坐标，用于指定如何将纹理图像映射到表面上。">纹理坐标</abbr>，我使用对象坐标。也就是说，一个点的 3D 纹理坐标与其在空间中的位置相同，在定义环面的对象坐标系中。效果就像从带有 3D 棋盘格图案的实心块中雕刻出环面一样，内外都着色。注意，你不会在环面的表面上看到彩色的正方形或矩形；你看到的是该表面与彩色立方体的交点。交点有各种各样的形状。这可能是这种特定 3D 纹理的缺点，但优点是没有纹理的拉伸和扭曲。计算 3D 棋盘格的代码与 2D 情况相同，只是使用三个对象坐标而不是两个纹理坐标。</p>
<p>自然看起来的纹理通常有一些随机性元素。我们不能使用真正的随机性，否则每次绘制纹理时看起来都会不同。然而，可以在计算纹理的算法中加入某种伪随机性。但我们不希望纹理中的颜色看起来完全随机 - 图案中必须有一定的图案！许多自然看起来的过程纹理都是基于一种称为 <strong>Perlin 噪声</strong> 的伪随机性，以 Ken Perlin 命名，他在 1983 年发明了这个算法。上面的第三个环面使用了直接基于 Perlin 噪声的 3D <abbr title="物体上某一点到另一点在某些属性上的变化。最常见的类型是图像纹理。当图像纹理应用于表面时，表面颜色会因点而异。">纹理</abbr>。第四个环面上的 "大理石 " 纹理在计算中使用 Perlin 噪声作为组件。两种纹理都是 3D 的，但类似的 2D 版本也是可能的。（我不知道 Perlin 噪声的算法。我从 <a href="https://github.com/ashima/webgl-noise">https://github.com/ashima/webgl-noise</a> 复制了 <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> 代码。该代码根据 MIT 风格的开源许可证发布，因此可以在任何项目中自由使用。）</p>
<p>在示例程序中，通过一个函数 <em>snoise(v)</em> 计算 3D Perlin 噪声，其中 <em>v</em> 是一个 <em>vec3</em>，函数的输出是一个范围在 -1.0 到 1.0 之间的 <em>float</em>。这里是计算过程：</p>
<div class="highlight"><pre><span></span><code><span class="kr">float</span><span class="w"> </span><span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">snoise</span><span class="p">(</span><span class="nx">scale</span><span class="o">*</span><span class="nx">v_objCoords</span><span class="p">);</span>
<span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.75</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">value</span><span class="o">*</span><span class="mf">0.25</span><span class="p">;</span><span class="w"> </span><span class="c1">// 映射到 0.5 到 1.0 的范围</span>
<span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="nx">value</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
</code></pre></div>
<p>这里，<em>v_objCoords</em> 是一个包含正在纹理化点的 3D 对象坐标的变化变量，scale 是一个纹理变换，用于适应纹理到环面的大小。由于 <em>snoise()</em> 的输出在 -1.0 和 1.0 之间变化，value 从 0.5 变化到 1.0，纹理的颜色从淡紫色到白色。第三个环面上看到的颜色变化是 Perlin 噪声的特征。图案有些随机，但它有规则的、大小相似的特征。通过正确的缩放和着色，基本的 Perlin 噪声可以制成一个不错的云纹理。</p>
<p>插图中第四个环面上的大理石纹理是通过在规则的、周期性图案中添加一些噪声来制作的。基本技术可以产生各种有用的纹理。起始点是一个变量的周期性函数，其值在 0.0 和 1.0 之间。要获得 2D 或 3D 中的周期性图案，函数的输入可以从纹理坐标计算得出。不同的函数可以产生非常不同的效果。这里显示的三种图案分别使用函数 <em>(1.0+sin(t))/2.0, abs(sin(t))</em> 和 <em>(t−floor(t))</em>：</p>
<p><a class="glightbox" href="../../../en/c7/procedural-textures-periodic.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/procedural-textures-periodic.png" /></a></p>
<p>在第二张图像中，取 <em>sin(t)</em> 的绝对值比第一张图像中的普通 <em>sine</em> 函数产生更窄、更尖锐的暗带。这是用于插图中大理石纹理的函数。第三张图像中的尖锐不连续可能是一个有趣的视觉效果。</p>
<p>要从一个变量的函数 <em>f(t)</em> 获得 2D <abbr title="使用图像的副本填充二维形状的内部。可以根据需要水平和垂直重复图像，以覆盖形状。">图案</abbr>，我们可以使用一个 <em>vec2</em>，v 的函数，定义为 <em>f(a</em>v.x+b<em>v.y)</em>，其中 a 和 b 是常数。a 和 b 的值决定了图案中彩色带的方向和间距。对于 3D <abbr title="使用图像的副本填充二维形状的内部。可以根据需要水平和垂直重复图像，以覆盖形状。">图案</abbr>，我们将使用 <em>f(a</em>v.x+b<em>v.y+c</em>v.z)*。</p>
<p>要向图案添加噪声，将 Perlin 噪声函数添加到函数的输入中。对于 3D <abbr title="使用图像的副本填充二维形状的内部。可以根据需要水平和垂直重复图像，以覆盖形状。">图案</abbr>，函数将变为</p>
<div class="highlight"><pre><span></span><code><span class="nx">f</span><span class="p">(</span><span class="w"> </span><span class="nx">a</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">b</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">c</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">d</span><span class="o">*</span><span class="nx">snoise</span><span class="p">(</span><span class="nx">e</span><span class="o">*</span><span class="nx">v</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
</code></pre></div>
<p>新的常数 <em>d</em> 和 <em>e</em> 决定了图案扰动的大小和强度。作为一个例子，创建环面大理石纹理的代码是：</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="o">*</span><span class="nx">scale</span><span class="p">;</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">3.0</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">z</span><span class="p">);</span>
<span class="nx">t</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mf">1.5</span><span class="o">*</span><span class="nx">snoise</span><span class="p">(</span><span class="nx">v</span><span class="p">);</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="nx">abs</span><span class="p">(</span><span class="nx">sin</span><span class="p">(</span><span class="nx">t</span><span class="p">));</span>
<span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="nx">sqrt</span><span class="p">(</span><span class="nx">value</span><span class="p">));</span>
</code></pre></div>
<p>（最后添加的 <em>sqrt</em> 是为了使彩色带比没有它时更尖锐。）</p>
<p>以下演示允许你将各种 3D 纹理应用到不同的对象上。演示中使用的过程纹理只是可能性的一小部分。</p>
<p><iframe src="../../../en/demos/c7/procedural-textures.html" width="680" height="480"></iframe></p>
</div>
<div class="tabbed-block">
<p>Up until now, all of our textures have been image textures. With an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>, a color is computed by <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the image, based on a pair of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. The image essentially defines a function that takes <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates as input and returns a color as output. However, there are other ways to define such functions besides looking up values in an image. A <strong><abbr title="A texture for which the value at a given set of texture coordinates is computed as a mathematical function of the coordinates, as opposed to an image texture where the value is obtained by sampling an image.">procedural texture</abbr></strong> is defined by a function whose value is computed rather than looked up. That is, the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates are used as input to a code segment whose output is the corresponding color value for the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.</p>
<p>In <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>, procedural textures can be defined in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>. The idea is simple: Take a <em>vec2</em> representing a set of <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. Then, instead of using a <em>sampler2D</em> to look up a color, use the <em>vec2</em> as input to some mathematical computation that computes a vec4 representing a color. In theory any computation could be used, as long as the components of the <em>vec4</em> are in the range 0.0 to 1.0.</p>
<p>We can even extend the idea to 3D textures. 2D textures use a <em>vec2</em> as <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. For 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, we use a <em>vec3</em>. Instead of mapping points on a plane to color, a 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> maps points in space to colors. It's possible to have 3D textures that are similar to image textures. That is, a color value is stored for each point in a 3D grid, and the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is sampled by looking up colors in the grid. However, a 3D grid of colors takes up a lot of memory. On the other hand, 3D procedural textures use no memory resources and use very little more computational resources than 2D procedural textures.</p>
<p>So, what can be done with procedural textures? In fact, quite a lot. There is a large body of theory and practice related to procedural textures. We will look at a few of the possibilities. Here's a <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>, textured using four different procedural textures. The images are from the demo shown at the end of this subsection:</p>
<p><a class="glightbox" href="../../../en/c7/procedural-textures-torus.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/procedural-textures-torus.png" /></a></p>
<p>The <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> on the left uses a 2D <abbr title="A texture for which the value at a given set of texture coordinates is computed as a mathematical function of the coordinates, as opposed to an image texture where the value is obtained by sampling an image.">procedural texture</abbr> representing a checkerboard pattern. The 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates were provided, as usual, as values of a <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variable in the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program. The checkerboard pattern is regular grid of equal-sized colored squares, but, as with any 2D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, the pattern is stretched and distorted when it is mapped to the curved surface of the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>. Given <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates in the <abbr title="A variable that is used to communicate values from the vertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline. A varying variable is assigned a value in the vertex shader. The value of the variable in the fragment shader for a pixel in the primitive is obtained by interpolating the values from the vertices of the primitive. (In newer versions of GLSL, which support additional shader stages, the term &quot;varying variable&quot; is replaced by the more general terms &quot;in variable&quot; and &quot;out variable,&quot; which refer to variables that are used for input to or output from a shader.)">varying variable</abbr> <em>v_texCoords</em>, the color value for the checkerboard <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can be computed as follows in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec4</span><span class="w"> </span><span class="nx">color</span><span class="p">;</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">floor</span><span class="p">(</span><span class="nx">v_texCoords</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">scale</span><span class="p">);</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">floor</span><span class="p">(</span><span class="nx">v_texCoords</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">scale</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">mod</span><span class="p">(</span><span class="nx">a</span><span class="o">+</span><span class="nx">b</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// a+b is odd</span>
<span class="w">    </span><span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"> </span><span class="c1">// pink</span>
<span class="p">}</span>
<span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// a+b is even</span>
<span class="w">    </span><span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="w"> </span><span class="mf">0.6</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"> </span><span class="c1">// light blue</span>
<span class="p">}</span>
</code></pre></div>
<p>The <em>scale</em> in the second and third lines represents a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation that is used to adapt the size of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to the object that is being textured. (The <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> range from 0 to 1; without the <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr>, only one square in the checkerboard pattern would be mapped to the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>. For the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> in the picture, <em>scale</em> is 8.) The floor function computes the largest integer less than or equal to its parameter, so a and b are integers. The value of <em>mod(a+b,2.0)</em> is either 0.0 or 1.0, so the test in the fourth line tests whether <em>a+b</em> is even or odd. The idea here is that when either a or b increases or decreases by 1, <em>a+b</em> will change from even to odd or from odd to even; that ensures that neighboring squares in the pattern will be differently colored.</p>
<p>The second <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> in the illustration uses a 3D checkerboard pattern. The 3D pattern is made up of a grid of cubes that alternate in color in all three directions. For the 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates on the cube, I use <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr>. That is, the 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for a point are the same as its position in space, in the object <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> in which the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> is defined. The effect is like carving the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> out of a solid block that is colored, inside and out, with a 3D checkerboard pattern. Note that you don't see colored squares or rectangles on the surface of the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>; you see the intersections of that surface with colored cubes. The intersections have a wide variety of shapes. That might be a disadvantage for this particular 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, but the advantage is that there is no stretching and distortion of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. The code for computing the 3D checkerboard is the same as for the 2D case, but using three <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> instead of two <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates.</p>
<p>Natural-looking textures often have some element of randomness. We can't use actual randomness, since then the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> would look different every time it is drawn. However, some sort of pseudo-randomness can be incorporated into the algorithm that computes a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. But we don't want the colors in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to look completely random—there has to be some sort of pattern in the pattern! Many natural-looking procedural textures are based on a type of pseudo-randomness called <strong><abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr></strong>, named after Ken Perlin who invented the algorithm in 1983. The third <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> in the above illustration uses a 3D <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> based directly on <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr>. The "marble" <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> on the fourth <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> uses <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr> as a component in the computation. Both textures are 3D, but similar 2D versions are also possible. (I don't know the algorithm for <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr>. I copied the <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> code from <a href="https://github.com/ashima/webgl-noise">https://github.com/ashima/webgl-noise</a>. The code is published under an MIT-style open source license, so that it can be used freely in any project.)</p>
<p>In the sample program, 3D <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr> is computed by a function <em>snoise(v)</em>, where <em>v</em> is a <em>vec3</em> and the output of the function is a <em>float</em> in the range −1.0 to 1.0. Here is the computation:</p>
<div class="highlight"><pre><span></span><code><span class="kr">float</span><span class="w"> </span><span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">snoise</span><span class="p">(</span><span class="w"> </span><span class="nx">scale</span><span class="o">*</span><span class="nx">v_objCoords</span><span class="w"> </span><span class="p">);</span>
<span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.75</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">value</span><span class="o">*</span><span class="mf">0.25</span><span class="p">;</span><span class="w"> </span><span class="c1">// map to the range 0.5 to 1.0</span>
<span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="nx">value</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
</code></pre></div>
<p>Here, <em>v_objCoords</em> is a <abbr title="A variable that is used to communicate values from the vertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline. A varying variable is assigned a value in the vertex shader. The value of the variable in the fragment shader for a pixel in the primitive is obtained by interpolating the values from the vertices of the primitive. (In newer versions of GLSL, which support additional shader stages, the term &quot;varying variable&quot; is replaced by the more general terms &quot;in variable&quot; and &quot;out variable,&quot; which refer to variables that are used for input to or output from a shader.)">varying variable</abbr> containing the 3D <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> of the point that is being textured, and scale is a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation that adapts the size of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> to the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>. Since the output of <em>snoise()</em> varies between −1.0 and 1.0, value varies from 0.5 to 1.0, and the color for the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> ranges from pale magenta to white. The <em>color</em> variation that you see on the third <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> is characteristic of <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr>. The pattern is somewhat random, but it has regular, similarly sized features. With the right <abbr title="A geometric transform that multiplies each coordinate of a point by a number called the scaling factor. Scaling increases or decreases the size of an object, but also moves its points closer to or farther from the origin. Scaling can be uniform—the same in every direction—or non-uniform—with a different scaling factor in each coordinate direction. A negative scaling factor can be used to apply a reflection.">scaling</abbr> and coloration, basic <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr> can make a decent cloud <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.</p>
<p>The marble <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> on the fourth <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> in the illustration is made by adding some noise to a regular, periodic pattern. The basic technique can produce a wide variety of useful textures. The starting point is a periodic function of one variable, with values between 0.0 and 1.0. To get a periodic pattern in 2D or 3D, the input to the function can be computed from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates. Different functions can produce very different effects. The three patterns shown here use the functions <em>(1.0+sin(t))/2.0, abs(sin(t))</em> and <em>(t−floor(t))</em>, respectively:</p>
<p><a class="glightbox" href="../../../en/c7/procedural-textures-periodic.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/procedural-textures-periodic.png" /></a></p>
<p>In the second image, taking the absolute value of <em>sin(t)</em> produces narrower, sharper dark bands than the plain <em>sine</em> function in the first image. This is the function that is used for the marble <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> in the illustration. The sharp discontinuity in the third image can be an interesting visual effect.</p>
<p>To get the 2D pattern from a function <em>f(t)</em> of one variable, we can use a function of a <em>vec2</em>, v, defined as <em>f(a*v.x+b*v.y)</em>, where a and b are constants. The values of a and b determine the orientation and spacing of the color bands in the pattern. For a 3D pattern, we would use <em>f(a*v.x+b*v.y+c*v.z)</em>.</p>
<p>To add noise to the pattern, add a <abbr title="A technique invented by Ken Perlin in 1983 that is used in the computation of natural-looking procedural textures. A Perlin noise function has numerical inputs (usually 2 or 3) and produces an output number in the range -1.0 to 1.0. The output is pseudo-random, but has some regularity, with features that are similarly sized and regularly distributed, and with variation on several scales.">Perlin noise</abbr> function to the input of the function. For a 3D pattern, the function would become</p>
<div class="highlight"><pre><span></span><code><span class="nx">f</span><span class="p">(</span><span class="w"> </span><span class="nx">a</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">b</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">c</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">d</span><span class="o">*</span><span class="nx">snoise</span><span class="p">(</span><span class="nx">e</span><span class="o">*</span><span class="nx">v</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
</code></pre></div>
<p>The new constants <em>d</em> and <em>e</em> determine the size and intensity of the perturbations to the pattern. As an example, the code that creates the marble <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> for the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> is:</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="o">*</span><span class="nx">scale</span><span class="p">;</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">v</span><span class="p">.</span><span class="nx">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">2.0</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">3.0</span><span class="o">*</span><span class="nx">v</span><span class="p">.</span><span class="nx">z</span><span class="p">);</span>
<span class="nx">t</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mf">1.5</span><span class="o">*</span><span class="nx">snoise</span><span class="p">(</span><span class="nx">v</span><span class="p">);</span>
<span class="kr">float</span><span class="w"> </span><span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="nx">abs</span><span class="p">(</span><span class="nx">sin</span><span class="p">(</span><span class="nx">t</span><span class="p">));</span>
<span class="nx">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec3</span><span class="p">(</span><span class="nx">sqrt</span><span class="p">(</span><span class="nx">value</span><span class="p">));</span>
</code></pre></div>
<p>(The <em>sqrt</em> at the end was added to make the color bands even sharper than they would be without it.)</p>
<p>The following demo lets you apply a variety of 3D textures to different objects. The procedural textures used in the demo are just a small sample of the possibilities.</p>
<p><iframe src="../../../en/demos/c7/procedural-textures.html" width="680" height="480"></iframe></p>
</div>
</div>
</div>
<h2 id="734-凹凸贴图">7.3.4 凹凸贴图<a class="headerlink" href="#734-凹凸贴图" title="Permanent link">&para;</a></h2>
<p><strong>Bumpmaps</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">中文</label><label for="__tabbed_5_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>So far, the only textures that we have encountered have affected color. Whether they were image textures, environment maps, or procedural textures, their effect has been to vary the color on the surfaces to which they were applied. But, more generally, <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can refer to variation in any property. One example is <strong><abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr></strong>, where the property that is modified by the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to the surface. A <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> determines how light is reflected by the surface, which is a major visual clue to the direction that the surface faces. Modifying the normal vectors has the effect of modifying the apparent orientation of the surface, as least with respect to the way it reflects light. It can add the appearance of roughness or "bumps" to the surface. The effect can be visually similar to changing the positions of points on the surface, but with <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> the change in appearance is achieved without actually changing the surface geometry. The alternative approach of modifying the actual geometry, which is called "<abbr title="A technique used to modify a polygonal mesh by moving, or displacing, the vertices of the mesh.">displacement mapping</abbr>," can give better results but requires a lot more computational and memory resources.</p>
<p>The typical way to do <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> is with a <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>, is a <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr> image in which the variation in color is used to specify the amount by which points on the surface are (or appear to be) displaced. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> is mapped to a surface in the same way as an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>, using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates that are supplied as an <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variable or generated computationally. But instead of being used to modify the color of a <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, the color value from the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> is used to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> that goes into the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation that computes the color of the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> that is used in this way is also called a bump map. I'm not sure that my implementation of this idea is optimal, but it can produce pretty good results.</p>
<p>Here are two examples. For each example, a bumpmapped <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> is shown next to the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> that was applied to the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>:</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap.png" /></a></p>
<p>In the first example, the gray dots in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> produce the appearance of bumps on the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>. The darker the color from the map, the greater apparent displacement of the point on the surface. The black centers of the dots map to the tops of the bumps. For the second example, the dark curves in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> seem to produce deep grooves in the surface. As is usual for textures, the height maps have been stretched to cover the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>, which distorts the shape of the features from the map.</p>
<p>To see how <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> can be implemented, let's first imagine that we want to apply it to a one-dimensional "surface." Consider a <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to a point on the surface, and suppose that a <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is applied to the surface. Take a <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, shown in black in the following illustration, that points in the direction in which the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr> value is decreasing.</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap-vectors-1D.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap-vectors-1D.png" /></a></p>
<p>We want the surface to appear as if it is tilted, as shown in the middle of the illustration. (I'm assuming here that darker colors in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> correspond to smaller heights.) Literally tilting the surface would change the direction of the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. We can get the same change in the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> by adding some multiple of the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> from the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> to the original <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>, as shown on the right above. Changing the number that is multiplied by the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> changes the degree of tilting of the surface. Increasing the multiplier gives a stronger bump effect. Using a negative multiple will tilt the surface in the opposite direction, which will transform "bumps" into "dimples," and vice versa. I will refer to the multiplier as the <em>bump strength</em>.</p>
<p>Things get a lot more complicated for two-dimensional surfaces in 3D space. A 1D "surface" can only be tilted left or right. On a 2D surface, there are infinitely many directions to tilt the surface. Note that the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points in the direction of tilt points along the surface, not perpendicular to the surface. A <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points along a surface is called a tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> to the surface. To do bump mapping, we need a tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> for each point on the surface. Tangent vectors will have to be provided, along with normal vectors, as part of the data for the surface. For my version of <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr>, the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that we need should be coordinated with the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for the surface: The tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> should point in the direction in which the s coordinate in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates is increasing.</p>
<p>In fact, to properly account for variation in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>, we need a second tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. The second tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> is perpendicular both to the normal and to the first tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. It is commonly called the "binormal" <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, and it can be computed from the normal and the tangent. (The binormal should point in the direction in which the t <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinate is increasing, but whether that can be exactly true will depend on the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> mapping. As long as it's not too far off, the result should be OK.)</p>
<p>Now, to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>, proceed as follows: Sample the height maps at two points, separated by a small difference in the s coordinate. Let a be the difference between the two values; a represents the rate at which the height value is changing in the direction of the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> (which, remember, points in the s direction along the surface). Then sample the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> at two points separated by a small difference in the t coordinate, and let b be the difference between the two values, so that b represents the rate at which the height value is changing in the direction of the binormal <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. Let D be the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> a*T + b*B, where T is the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> and B is the binormal. Then add D, or a multiple of D, to the original <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to produce the modified normal that will be used in the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation. (If you know multivariable calculus, what we are doing here amounts to using approximations for directional derivatives and the <abbr title="A pattern of color produced by assigning colors to certain reference points and computing color for other points by interpolating or extrapolating colors from the reference points. The effect is a color progression along line segments between reference points. Different rules for extending the colors beyond those lines produce different types of gradient, such as linear gradients and radial gradients.">gradient</abbr> <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> of a height function on the surface.)</p>
<p>I have tried to explain the procedure in the following illustration. You need to visualize the situation in 3D, noting that the normal, tangent, and binormal vectors are perpendicular to each other. The white arrows on the left are actually multiples of the binormal and tangent vectors, with lengths given by the change in color between two <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>.</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap-vectors.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap-vectors.png" /></a></p>
<p>The sample program <a href="../../../en/source/webgl/bumpmap.html">webgl/bumpmap.html</a> demonstrates <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr>. The two bumpmapped toruses in the above illustration are from that program. When you run the program, pay attention to the specular highlights! They will help you to see how a bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> differs from an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>. The effect might be more obvious if you change the "Diffuse Color" from white to some other color. The <abbr title="A material property that represents the proportion of incident light that is reflected specularly by a surface.">specular color</abbr> is always white.</p>
<p>(For this program, I had to add tangent vectors to my objects. I chose three objects—a cube, a cylinder, and a <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>—for which tangent vectors were relatively easy to compute. But, honestly, it took me a while to get all the tangent vectors pointing in the correct directions.)</p>
<p>The <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> is implemented in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in the sample program. The essential problem is how to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. Let's examine the <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> code that does the work:</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">v_normal</span><span class="w"> </span><span class="p">);</span>
<span class="nx">vec3</span><span class="w"> </span><span class="nx">tangent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">v_tangent</span><span class="w"> </span><span class="p">);</span>
<span class="nx">vec3</span><span class="w"> </span><span class="nx">binormal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">cross</span><span class="p">(</span><span class="nx">normal</span><span class="p">,</span><span class="nx">tangent</span><span class="p">);</span>

<span class="kr">float</span><span class="w"> </span><span class="nx">bm0</span><span class="p">,</span><span class="w"> </span><span class="nx">bmUp</span><span class="p">,</span><span class="w"> </span><span class="nx">bmRight</span><span class="p">;</span><span class="w">  </span><span class="c1">// Samples from the bumpmap at three texels.</span>
<span class="nx">bm0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w"> </span>
<span class="nx">bmUp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">vec2</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="o">/</span><span class="nx">bumpmapSize</span><span class="p">.</span><span class="nx">y</span><span class="p">)</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w"> </span>
<span class="nx">bmRight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">vec2</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nx">bumpmapSize</span><span class="p">.</span><span class="nx">x</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span>

<span class="nx">vec3</span><span class="w"> </span><span class="nx">bumpVector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">bmRight</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">bm0</span><span class="p">)</span><span class="o">*</span><span class="nx">tangent</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="nx">bmUp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">bm0</span><span class="p">)</span><span class="o">*</span><span class="nx">binormal</span><span class="p">;</span>
<span class="nx">normal</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">bumpmapStrength</span><span class="o">*</span><span class="nx">bumpVector</span><span class="p">;</span>
<span class="nx">normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="o">*</span><span class="nx">normal</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>The first three lines compute the normal, tangent, and binormal unit vectors. The normal and tangent come from varying variables whose values are interpolated from <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variables, which were in turn input to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program from the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side. The binormal, which is perpendicular to both the normal and the tangent, is computed as the <abbr title="A vector product of two 3D vectors. The cross product of v and w is a vector that is perpendicular to both v and w and whose length is equal to the absolute value of the sine of the angle between v and w. If v=(x,y,z) and w=(a,b,c), then their cross product is the vector (yc-zb,za-xc,xb-ya).">cross product</abbr> of the normal and tangent (<a href="../../c3/s5/#351-向量和向量数学">Subsection 3.5.1</a>).</p>
<p>The next four lines get the values of the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> at the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> that corresponds to the surface point that is being processed and at two neighboring <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>. <em>bm0</em> is the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> value at the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, whose coordinates in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> are given by the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, <em>v_texCoords</em>. The value for <em>bm0</em> is the red <abbr title="One of the numbers used in a color model to specify a color. For example, in the RGB color model, a color is specified by three color components representing the amounts of red, green, and blue in the color.">color component</abbr> from the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>; since the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr>, all of its color components have the same value. bmUp is the value from the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> above the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>; the coordinates are computed by adding <em>1.0/bumpmapSize.y</em> to the y-coordinate of the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, where bumpmapSize is a <abbr title="Variables that represent input to a shader program in a programmable graphics pipeline. A uniform variable has the same value at every vertex and at every pixel of a primitive.">uniform variable</abbr> that gives the size of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image, in <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>. Since <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates in the image run from 0.0 to 1.0, the difference in the y-coordinates of the two <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr> is <em>1.0/bumpmapSize.y</em>. Similarly, bmRight is the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> value for the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> to the right of the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. I should note that the <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr> for the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> was set to <em>gl.NEAREST</em>, because we need to read the actual value from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, not a value averaged from several <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>, as would be returned by the default <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr>.</p>
<p>The two vectors <em>(bmRight−bm0)*tangent</em> and <em>(bmUp−bm0)*binormal</em> are the two white vectors in the above illustration. Their sum is <em>bumpVector</em>. A multiple of that sum is added to the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to give the modified <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. The multiplier, <em>bumpmapStrength</em>, is a uniform float variable.</p>
<p>All of the calculations so far have been done in the object <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr>. The resulting normal depends only on the original <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr>, not on any transformation that has been applied. The <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> still has to be transformed into <abbr title="The coordinate system on 3D space defined by the viewer. In eye coordinates in OpenGL 1.1, the viewer is located at the origin, looking in the direction of the negative z-axis, with the positive y-axis pointing upwards, and the positive x-axis pointing to the right. The modelview transformation maps objects into the eye coordinate system, and the projection transform maps eye coordinates to clip coordinates.">eye coordinates</abbr> before it can be used in the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation. That transformation is done in the last line of code shown above.</p>
</div>
<div class="tabbed-block">
<p>So far, the only textures that we have encountered have affected color. Whether they were image textures, environment maps, or procedural textures, their effect has been to vary the color on the surfaces to which they were applied. But, more generally, <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can refer to variation in any property. One example is <strong><abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr></strong>, where the property that is modified by the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to the surface. A <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> determines how light is reflected by the surface, which is a major visual clue to the direction that the surface faces. Modifying the normal vectors has the effect of modifying the apparent orientation of the surface, as least with respect to the way it reflects light. It can add the appearance of roughness or "bumps" to the surface. The effect can be visually similar to changing the positions of points on the surface, but with <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> the change in appearance is achieved without actually changing the surface geometry. The alternative approach of modifying the actual geometry, which is called "<abbr title="A technique used to modify a polygonal mesh by moving, or displacing, the vertices of the mesh.">displacement mapping</abbr>," can give better results but requires a lot more computational and memory resources.</p>
<p>The typical way to do <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> is with a <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>, is a <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr> image in which the variation in color is used to specify the amount by which points on the surface are (or appear to be) displaced. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> is mapped to a surface in the same way as an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>, using <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates that are supplied as an <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variable or generated computationally. But instead of being used to modify the color of a <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, the color value from the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> is used to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> that goes into the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation that computes the color of the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>. A <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> that is used in this way is also called a bump map. I'm not sure that my implementation of this idea is optimal, but it can produce pretty good results.</p>
<p>Here are two examples. For each example, a bumpmapped <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr> is shown next to the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> that was applied to the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>:</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap.png" /></a></p>
<p>In the first example, the gray dots in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> produce the appearance of bumps on the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>. The darker the color from the map, the greater apparent displacement of the point on the surface. The black centers of the dots map to the tops of the bumps. For the second example, the dark curves in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> seem to produce deep grooves in the surface. As is usual for textures, the height maps have been stretched to cover the <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>, which distorts the shape of the features from the map.</p>
<p>To see how <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> can be implemented, let's first imagine that we want to apply it to a one-dimensional "surface." Consider a <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to a point on the surface, and suppose that a <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is applied to the surface. Take a <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, shown in black in the following illustration, that points in the direction in which the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr> value is decreasing.</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap-vectors-1D.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap-vectors-1D.png" /></a></p>
<p>We want the surface to appear as if it is tilted, as shown in the middle of the illustration. (I'm assuming here that darker colors in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> correspond to smaller heights.) Literally tilting the surface would change the direction of the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. We can get the same change in the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> by adding some multiple of the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> from the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> to the original <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>, as shown on the right above. Changing the number that is multiplied by the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> changes the degree of tilting of the surface. Increasing the multiplier gives a stronger bump effect. Using a negative multiple will tilt the surface in the opposite direction, which will transform "bumps" into "dimples," and vice versa. I will refer to the multiplier as the <em>bump strength</em>.</p>
<p>Things get a lot more complicated for two-dimensional surfaces in 3D space. A 1D "surface" can only be tilted left or right. On a 2D surface, there are infinitely many directions to tilt the surface. Note that the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points in the direction of tilt points along the surface, not perpendicular to the surface. A <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points along a surface is called a tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> to the surface. To do bump mapping, we need a tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> for each point on the surface. Tangent vectors will have to be provided, along with normal vectors, as part of the data for the surface. For my version of <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr>, the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that we need should be coordinated with the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates for the surface: The tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> should point in the direction in which the s coordinate in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates is increasing.</p>
<p>In fact, to properly account for variation in the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr>, we need a second tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. The second tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> is perpendicular both to the normal and to the first tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. It is commonly called the "binormal" <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>, and it can be computed from the normal and the tangent. (The binormal should point in the direction in which the t <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinate is increasing, but whether that can be exactly true will depend on the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> mapping. As long as it's not too far off, the result should be OK.)</p>
<p>Now, to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>, proceed as follows: Sample the height maps at two points, separated by a small difference in the s coordinate. Let a be the difference between the two values; a represents the rate at which the height value is changing in the direction of the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> (which, remember, points in the s direction along the surface). Then sample the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> at two points separated by a small difference in the t coordinate, and let b be the difference between the two values, so that b represents the rate at which the height value is changing in the direction of the binormal <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. Let D be the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> a*T + b*B, where T is the tangent <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> and B is the binormal. Then add D, or a multiple of D, to the original <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to produce the modified normal that will be used in the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation. (If you know multivariable calculus, what we are doing here amounts to using approximations for directional derivatives and the <abbr title="A pattern of color produced by assigning colors to certain reference points and computing color for other points by interpolating or extrapolating colors from the reference points. The effect is a color progression along line segments between reference points. Different rules for extending the colors beyond those lines produce different types of gradient, such as linear gradients and radial gradients.">gradient</abbr> <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> of a height function on the surface.)</p>
<p>I have tried to explain the procedure in the following illustration. You need to visualize the situation in 3D, noting that the normal, tangent, and binormal vectors are perpendicular to each other. The white arrows on the left are actually multiples of the binormal and tangent vectors, with lengths given by the change in color between two <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>.</p>
<p><a class="glightbox" href="../../../en/c7/bumpmap-vectors.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/bumpmap-vectors.png" /></a></p>
<p>The sample program <a href="../../../en/source/webgl/bumpmap.html">webgl/bumpmap.html</a> demonstrates <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr>. The two bumpmapped toruses in the above illustration are from that program. When you run the program, pay attention to the specular highlights! They will help you to see how a bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> differs from an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>. The effect might be more obvious if you change the "Diffuse Color" from white to some other color. The <abbr title="A material property that represents the proportion of incident light that is reflected specularly by a surface.">specular color</abbr> is always white.</p>
<p>(For this program, I had to add tangent vectors to my objects. I chose three objects—a cube, a cylinder, and a <abbr title="A 3D geometric object having the shape of a doughnut (or bagel).">torus</abbr>—for which tangent vectors were relatively easy to compute. But, honestly, it took me a while to get all the tangent vectors pointing in the correct directions.)</p>
<p>The <abbr title="Using a texture to modify the normal vectors on a surface, to give the appearance of variations in height without actually modifying the geometry of the surface.">bumpmapping</abbr> is implemented in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in the sample program. The essential problem is how to modify the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. Let's examine the <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> code that does the work:</p>
<div class="highlight"><pre><span></span><code><span class="nx">vec3</span><span class="w"> </span><span class="nx">normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">v_normal</span><span class="w"> </span><span class="p">);</span>
<span class="nx">vec3</span><span class="w"> </span><span class="nx">tangent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">v_tangent</span><span class="w"> </span><span class="p">);</span>
<span class="nx">vec3</span><span class="w"> </span><span class="nx">binormal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">cross</span><span class="p">(</span><span class="nx">normal</span><span class="p">,</span><span class="nx">tangent</span><span class="p">);</span>

<span class="kr">float</span><span class="w"> </span><span class="nx">bm0</span><span class="p">,</span><span class="w"> </span><span class="nx">bmUp</span><span class="p">,</span><span class="w"> </span><span class="nx">bmRight</span><span class="p">;</span><span class="w">  </span><span class="c1">// Samples from the bumpmap at three texels.</span>
<span class="nx">bm0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w"> </span>
<span class="nx">bmUp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">vec2</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="o">/</span><span class="nx">bumpmapSize</span><span class="p">.</span><span class="nx">y</span><span class="p">)</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span><span class="w"> </span>
<span class="nx">bmRight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">texture2D</span><span class="p">(</span><span class="w"> </span><span class="nx">bumpmap</span><span class="p">,</span><span class="w"> </span><span class="nx">v_texCoords</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">vec2</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nx">bumpmapSize</span><span class="p">.</span><span class="nx">x</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="p">).</span><span class="nx">r</span><span class="p">;</span>

<span class="nx">vec3</span><span class="w"> </span><span class="nx">bumpVector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">bmRight</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">bm0</span><span class="p">)</span><span class="o">*</span><span class="nx">tangent</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="nx">bmUp</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">bm0</span><span class="p">)</span><span class="o">*</span><span class="nx">binormal</span><span class="p">;</span>
<span class="nx">normal</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">bumpmapStrength</span><span class="o">*</span><span class="nx">bumpVector</span><span class="p">;</span>
<span class="nx">normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="o">*</span><span class="nx">normal</span><span class="w"> </span><span class="p">);</span>
</code></pre></div>
<p>The first three lines compute the normal, tangent, and binormal unit vectors. The normal and tangent come from varying variables whose values are interpolated from <abbr title="A property, such as color, of a graphical object. An image can be specified by the geometric shapes that it contains, together with their attributes.">attribute</abbr> variables, which were in turn input to the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program from the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side. The binormal, which is perpendicular to both the normal and the tangent, is computed as the <abbr title="A vector product of two 3D vectors. The cross product of v and w is a vector that is perpendicular to both v and w and whose length is equal to the absolute value of the sine of the angle between v and w. If v=(x,y,z) and w=(a,b,c), then their cross product is the vector (yc-zb,za-xc,xb-ya).">cross product</abbr> of the normal and tangent (<a href="../../c3/s5/#351-向量和向量数学">Subsection 3.5.1</a>).</p>
<p>The next four lines get the values of the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> at the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> that corresponds to the surface point that is being processed and at two neighboring <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>. <em>bm0</em> is the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> value at the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, whose coordinates in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> are given by the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates, <em>v_texCoords</em>. The value for <em>bm0</em> is the red <abbr title="One of the numbers used in a color model to specify a color. For example, in the RGB color model, a color is specified by three color components representing the amounts of red, green, and blue in the color.">color component</abbr> from the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>; since the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is <abbr title="Refers to a color scheme or image in which each color is a shade of gray (where the term &quot;shade of gray&quot; here includes black and white). Typically, 256 shades of gray are used. Grayscale is also called &quot;monochrome.&quot;">grayscale</abbr>, all of its color components have the same value. bmUp is the value from the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> above the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>; the coordinates are computed by adding <em>1.0/bumpmapSize.y</em> to the y-coordinate of the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr>, where bumpmapSize is a <abbr title="Variables that represent input to a shader program in a programmable graphics pipeline. A uniform variable has the same value at every vertex and at every pixel of a primitive.">uniform variable</abbr> that gives the size of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> image, in <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>. Since <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> coordinates in the image run from 0.0 to 1.0, the difference in the y-coordinates of the two <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr> is <em>1.0/bumpmapSize.y</em>. Similarly, bmRight is the <abbr title="An image in which the grayscale value represents a height, or elevation. Height maps can be used in displacement mapping to specify the amount of displacement.">height map</abbr> value for the <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> to the right of the current <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. I should note that the <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr> for the bumpmap <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> was set to <em>gl.NEAREST</em>, because we need to read the actual value from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, not a value averaged from several <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixels</abbr>, as would be returned by the default <abbr title="An operation that is used when applying a texture to an object, when the texture has to be shrunk to fit the object. For an image texture, a minification filter is applied to compute the color of a pixel when that pixel covers several pixels in the image.">minification filter</abbr>.</p>
<p>The two vectors <em>(bmRight−bm0)*tangent</em> and <em>(bmUp−bm0)*binormal</em> are the two white vectors in the above illustration. Their sum is <em>bumpVector</em>. A multiple of that sum is added to the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to give the modified <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. The multiplier, <em>bumpmapStrength</em>, is a uniform float variable.</p>
<p>All of the calculations so far have been done in the object <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr>. The resulting normal depends only on the original <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr>, not on any transformation that has been applied. The <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> still has to be transformed into <abbr title="The coordinate system on 3D space defined by the viewer. In eye coordinates in OpenGL 1.1, the viewer is located at the origin, looking in the direction of the negative z-axis, with the positive y-axis pointing upwards, and the positive x-axis pointing to the right. The modelview transformation maps objects into the eye coordinate system, and the projection transform maps eye coordinates to clip coordinates.">eye coordinates</abbr> before it can be used in the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation. That transformation is done in the last line of code shown above.</p>
</div>
</div>
</div>
<h2 id="735-环境映射">7.3.5 <abbr title="一种模拟物体表面类似镜面反射的方法。要从表面上反射的环境被表示为立方体贴图。为了确定纹理中哪个点在物体上的给定点可见，从视点反射到表面点的射线，并且与纹理立方体相交的反射射线。环境映射也称为反射映射。">环境映射</abbr><a class="headerlink" href="#735-环境映射" title="Permanent link">&para;</a></h2>
<p><strong>Environment Mapping</strong></p>
<div class="tabbed-set tabbed-alternate" data-tabs="6:2"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">中文</label><label for="__tabbed_6_2">英文</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="../../c5/s3/#535-反射和折射">5.3.5小节</a> 展示了如何在 <em><abbr title="一个用于3D图形的JavaScript库。该库实现了面向对象的场景图API。虽然它主要用于WebGL，但three.js也可以使用2D画布图形API渲染3D场景。">three.js</abbr></em> 中使用环境映射来使物体表面看起来反射了环境。环境映射使用立方体贴图纹理，实际上只是将立方体贴图纹理映射到表面上。它不会使物体反射其环境中的其他物体。我们可以通过添加一个天空盒——一个围绕场景的大立方体，将立方体贴图映射到其内部，来使它看起来好像物体反射了其环境。然而，物体只会看起来反射了天空盒。如果环境中有其他物体，它们不会出现在反射中。</p>
<p>示例程序 <a href="../../../en/source/webgl/skybox-and-env-map.html">webgl/<abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>-and-env-map.html</a> 在 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中实现了环境映射。程序展示了一个完全反射的物体在天空盒内部。场景中没有使用光照；天空盒和物体的颜色直接从立方体贴图纹理中获取。物体看起来像一面完美的镜子。这不是使用环境贴图的唯一方式。例如，可以使用光照方程计算基本物体颜色——甚至可以使用图像纹理——并将环境贴图与基本颜色混合，以给人一种有光泽但不是完全反射的表面的的外观。然而，示例程序的要点只是展示如何在 <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr> 中使用天空盒和环境贴图。用于实现这一点的着色器程序实际上相当短。</p>
<p>至于立方体贴图纹理本身，<a href="../../c6/s4/#644-立方体贴图纹理">6.4.4小节</a> 展示了如何将立方体贴图纹理加载为六个单独的图像，以及如何在 <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> 中使用 <em>samplerCube</em> 类型的变量访问该纹理。请记住，立方体贴图纹理是使用从原点指向立方体贴图纹理要采样的点的 3D 向量来采样的。</p>
<p>渲染天空盒很容易：绘制一个以原点为中心的大立方体，包围场景和摄像机位置。在片段着色器中给像素上色，使用从原点穿过正在渲染的立方体上的点的向量来采样立方体贴图纹理，以便立方体上某点的颜色与立方体贴图中相应点的颜色相同。请注意，由于在旋转视图时应该将纹理附加到立方体上，因此使用立方体的对象坐标来采样纹理。</p>
<p>在渲染天空盒的着色器程序中，顶点着色器只需要像通常一样计算 gl_Position，并将对象坐标作为变化变量传递给片段着色器。这是天空盒的顶点着色器源代码：</p>
<div class="highlight"><pre><span></span><code><span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">projection</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">modelview</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec4</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">modelview</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec4</span><span class="p">(</span><span class="nx">coords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="w">    </span><span class="nx">gl_Position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">projection</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_objCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>片段着色器简单地使用对象坐标通过采样立方体贴图纹理来获取片段颜色：</p>
<div class="highlight"><pre><span></span><code><span class="nx">precision</span><span class="w"> </span><span class="nx">mediump</span><span class="w"> </span><span class="kr">float</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">samplerCube</span><span class="w"> </span><span class="nx">skybox</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">gl_FragColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureCube</span><span class="p">(</span><span class="nx">skybox</span><span class="p">,</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>请注意，用于采样立方体贴图纹理的向量不必是单位向量；它只是必须指向正确的方向。</p>
<hr />
<p>要理解如何将立方体贴图纹理作为反射贴图应用到物体上，我们需要问自己，在物体上的某一点应该看到纹理中的哪个点？如果我们将纹理视为实际的环境，那么光线会从环境中来，击中物体，然后反射到观察者那里。我们只需要从观察者那里追踪那条光线回到物体，然后回到环境。反射光线的方向总是由法线向量决定的。考虑几何体的 2D 版本。你可以将其视为 3D 几何体的横截面：</p>
<p><a class="glightbox" href="../../../en/c7/cube-map-vectors.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cube-map-vectors.png" /></a></p>
<p>在这张插图中，虚线框代表立方体贴图纹理。（你真的应该将其视为在无限远处。）V 是从物体指向观察者的向量。N 是表面的法线向量。而 R 是 V 通过 N 的反射。R 指向立方体贴图中观察者在表面上某点可以看到的纹理元素；它是需要用来采样立方体贴图的向量。图片显示了表面上两个不同点的三个向量。在 <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> 中，R 可以被计算为 <em>−reflect(V, N)</em>。</p>
<p>如果同一个立方体贴图纹理也应用到天空盒上，它看起来就像物体反射了天空盒——但 <strong>只有</strong> 当没有对天空盒立方体应用变换时。原因是变换天空盒不会自动变换立方体贴图纹理。由于我们希望能够旋转视图，我们需要能够变换天空盒。我们希望反射物体看起来像是在反射变换后的天空盒位置，而不是原始位置。那种观察变换可以被视为对天空盒建模变换，以及场景中其他物体的变换。我们必须弄清楚如何使其适用于立方体贴图纹理。让我们思考一下在 2D 情况下，当我们将视图旋转 -30 度时会发生什么。这与将天空盒和物体旋转 30 度相同。在插图中，我将观察者画在与之前相同的位置，并旋转了场景。带有较淡虚线轮廓的正方形是天空盒。立方体贴图纹理没有移动：</p>
<p><a class="glightbox" href="../../../en/c7/cube-map-vectors-transformed.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cube-map-vectors-transformed.png" /></a></p>
<p>如果我们像以前一样计算 R 并用它来采样立方体贴图纹理，我们会得到纹理中的错误点。观察者应该看到的是 R 与天空盒相交的点，而不是 R 与纹理相交的点。正确的纹理点由向量 T 挑选出来。T 通过观察变换的逆变换 R 来计算。R 被观察变换旋转了；逆观察变换撤销了那个变换，将 T 放入与立方贴图相同的坐标系中。在这种情况下，由于 R 被旋转了 30 度，所以应用了 -30 度的旋转来计算 T。（这只是理解几何体的一种方式。如果你更愿意将立方体贴图视为与天空盒一起旋转，那么我们需要在采样纹理之前对纹理应用纹理变换——这也是说我们需要在采样纹理之前对 R 进行变换的另一种方式。）</p>
<p>在示例程序中，用来表示物体的着色器程序与用来渲染天空盒的程序不同。顶点着色器非常典型。注意，模型视图变换可以包括除了应用于整个场景的观察变换之外，还应用于物体的建模变换。以下是源代码：</p>
<div class="highlight"><pre><span></span><code><span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">projection</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">modelview</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">normal</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec4</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">modelview</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec4</span><span class="p">(</span><span class="nx">coords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="w">    </span><span class="nx">gl_Position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">projection</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">.</span><span class="nx">xyz</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normal</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>顶点着色器将眼睛坐标作为一个变化变量传递给片段着色器。在眼睛坐标中，观察者位于点 (0,0,0)，指向观察者的从表面到观察者的向量 V 就是 <em>−v_eyeCoords</em>。</p>
<p>片段着色器的源代码实现了上述采样立方体贴图纹理的算法。由于我们正在做完美反射，片段的颜色直接来自纹理：</p>
<div class="highlight"><pre><span></span><code><span class="nx">precision</span><span class="w"> </span><span class="nx">mediump</span><span class="w"> </span><span class="kr">float</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">vCoords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">samplerCube</span><span class="w"> </span><span class="nx">skybox</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat3</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat3</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">);</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="nx">reflect</span><span class="p">(</span><span class="nx">V</span><span class="p">,</span><span class="nx">N</span><span class="p">);</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">R</span><span class="p">;</span>
<span class="w">    </span><span class="nx">gl_FragColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureCube</span><span class="p">(</span><span class="nx">skybox</span><span class="p">,</span><span class="w"> </span><span class="nx">T</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p><em>inverseViewTransform</em> 是在 <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> 端从模型视图矩阵计算得出的，在应用了观察变换但尚未应用任何额外建模变换之后，使用以下命令：</p>
<div class="highlight"><pre><span></span><code><span class="nx">mat3</span><span class="p">.</span><span class="nx">fromMat4</span><span class="p">(</span><span class="nx">inverseViewTransform</span><span class="p">,</span><span class="w"> </span><span class="nx">modelview</span><span class="p">);</span>
<span class="nx">mat3</span><span class="p">.</span><span class="nx">invert</span><span class="p">(</span><span class="nx">inverseViewTransform</span><span class="p">,</span><span class="nx">inverseViewTransform</span><span class="p">);</span>
</code></pre></div>
<p>我们需要一个 <strong><em>mat3</em></strong> 来变换一个向量。第一行丢弃了模型视图矩阵的平移部分，将结果放在 <em>inverseViewTransform</em> 中。平移不影响向量，但在这个程序中观察变换只是旋转，所以平移部分无论如何都是零。第二行将 <em>inverseViewTransform</em> 转换成它的逆矩阵。</p>
</div>
<div class="tabbed-block">
<p><a href="../../c5/s3/#535-反射和折射">Subsection 5.3.5</a> showed how to use <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr> in <em><abbr title="一个用于3D图形的JavaScript库。该库实现了面向对象的场景图API。虽然它主要用于WebGL，但three.js也可以使用2D画布图形API渲染3D场景。">three.js</abbr></em> to make it look like the surface of an object reflects an environment. Environment mapping uses a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>, and it is really just a way of mapping a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> to the surface. It doesn't make the object reflect other objects in its environment. We can make it look as if the object is reflecting its environment by adding a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>—a large cube surrounding the scene, with the cubemap mapped onto its interior. However, the object will only seem to be reflecting the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>. And if there are other objects in the environment, they won't be part of the reflection.</p>
<p>The sample program <a href="../../../en/source/webgl/skybox-and-env-map.html">webgl/<abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>-and-env-map.html</a> implements <abbr title="A way of simulating mirror-like reflection from the surface of an object. The environment that is to be reflected from the surface is represented as a cubemap texture. To determine what point in the texture is visible at a given point on the object, a ray from the viewpoint is reflected from the surface point, and the reflected ray is intersected with the texture cube. Environment mapping is also called reflection mapping.">environment mapping</abbr> in <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>. The program shows a single fully reflective object inside a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>. No <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> is used in the scene; the colors for both the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> and the object are taken directly from the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. The object looks like a perfect mirror. This is not the only way of using an environment map. For example, a basic object color could be computed using the <abbr title="Using light sources in a 3D scene, so that the appearance of objects in the scene can be computed based on the interaction of light with the objects' material properties.">lighting</abbr> equation—perhaps even with an <abbr title="An image that is applied to a surface as a texture, so that it looks at if the image is &quot;painted&quot; onto the surface.">image texture</abbr>—and the environment map could be blended with the basic color to give the appearance of a shiny but not fully reflective surface. However, the point of the sample program is just to show how to use a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> and environment map in <abbr title="A 3D graphics API for use on web pages. WebGL programs are written in the JavaScript programming language and display their images in HTML canvas elements. WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with a few changes to adapt it to the JavaScript language and the Web environment.">WebGL</abbr>. The <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> programs that are used to do that are actually quite short.</p>
<p>As for the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> itself, <a href="../../c6/s4/#644-立方体贴图纹理">Subsection 6.4.4</a> showed how to load a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> as six separate images and how to access that <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> in <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr> using a variable of type <em>samplerCube</em>. Remember that a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is sampled using a 3D <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points from the origin towards the point on the cube where the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is to be sampled.</p>
<p>It's easy to render the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>: Draw a large cube, centered at the origin, enclosing the scene and the <abbr title="In 3D computer graphics, an object that combines the projection and viewing transforms into an abstraction that imitates a physical camera or eye.">camera</abbr> position. To color a <abbr title="A digital image is made up of rows and columns of small rectangles called pixels. To specify a digital image, a color is assigned to each pixel in the image.">pixel</abbr> in the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr>, sample the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> using a <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points from the origin through the point on the cube that is being rendered, so that the color of a point on the cube is the same as the color of the corresponding point in the cubemap. Note that it is the cube's <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> that are used to sample the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>, since the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> should be attached to the cube when we rotate the view.</p>
<p>In the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program for <abbr title="The process of producing a 2D image from a 3D scene description.">rendering</abbr> a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> just needs to compute gl_Position as usual and pass the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> on to the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in a <abbr title="A variable that is used to communicate values from the vertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline. A varying variable is assigned a value in the vertex shader. The value of the variable in the fragment shader for a pixel in the primitive is obtained by interpolating the values from the vertices of the primitive. (In newer versions of GLSL, which support additional shader stages, the term &quot;varying variable&quot; is replaced by the more general terms &quot;in variable&quot; and &quot;out variable,&quot; which refer to variables that are used for input to or output from a shader.)">varying variable</abbr>. Here is the <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> source code for the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">projection</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">modelview</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec4</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">modelview</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec4</span><span class="p">(</span><span class="nx">coords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="w">    </span><span class="nx">gl_Position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">projection</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_objCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<p>And the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> simply uses the <abbr title="The coordinate system in which the coordinates for points in an object are originally specified, before they are transformed by any modeling or other transform that will be applied to the object.">object coordinates</abbr> to get the fragment color by <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">precision</span><span class="w"> </span><span class="nx">mediump</span><span class="w"> </span><span class="kr">float</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">samplerCube</span><span class="w"> </span><span class="nx">skybox</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">gl_FragColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureCube</span><span class="p">(</span><span class="nx">skybox</span><span class="p">,</span><span class="w"> </span><span class="nx">v_objCoords</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>Note that the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that is used to sample a <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> does not have to be a <abbr title="A vector of length one.">unit vector</abbr>; it just has to point in the correct direction.</p>
<hr />
<p>To understand how a cube map <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> can be applied to an object as a reflection map, we have to ask what point from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> should be visible at a point on the object? If we think of the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> as an actual environment, then a ray of light would come from the environment, hit the object, and be reflected towards the viewer. We just have to trace that light ray back from the viewer to the object and then to the environment. The direction in which the light ray is reflected is determined, as always, by the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr>. Consider a 2D version of the geometry. You can think of this as a cross-section of the 3D geometry:</p>
<p><a class="glightbox" href="../../../en/c7/cube-map-vectors.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cube-map-vectors.png" /></a></p>
<p>In this illustration, the dotted box represents the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. (You really should think of it as being at infinite distance.) V is a <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that points from the object towards the viewer. N is the <abbr title="A normal vector to a surface at a point on that surface is a vector that is perpendicular to the surface at that point. Normal vectors to curves are defined similarly. Normal vectors are important for lighting calculations.">normal vector</abbr> to the surface. And R is the reflection of V through N. R points to the <abbr title="A pixel in a texture image.">texel</abbr> in the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> that is visible to the viewer at the point on the surface; it is the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> that is needed to sample the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. The picture shows the three vectors at two different points on the surface. In <abbr title="OpenGL Shader Language, the programming language that is used to write shader programs for use with OpenGL.">GLSL</abbr>, R can be computed as <em>−reflect(V, N)</em>.</p>
<p>If the same <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> is also applied to a <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, it will look as if the object is reflecting the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>—but <strong>only</strong> if no transformation has been applied to the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> cube. The reason is that transforming the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> does not automatically transform the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. Since we want to be able to rotate the view, we need to be able to transform the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>. And we want the reflected object to look like it is reflecting the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> in its transformed position, not in its original position. That <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transformation can be thought of as a <abbr title="A transformation that is applied to an object to map that object into the world coordinate system or into the object coordinate system for a more complex, hierarchical object.">modeling transformation</abbr> on the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, as well as on other objects in the scene. We have to figure out how to make it apply to the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. Let's think about what happens in the 2D case when we rotate the view by −30 degrees. That's the same as rotating the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr> and object by 30 degrees. In the illustration, I've drawn the viewer at the same position as before, and I have rotated the scene. The square with the fainter dotted outline is the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>. The <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr> hasn't moved:</p>
<p><a class="glightbox" href="../../../en/c7/cube-map-vectors-transformed.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="123" src="../../../en/c7/cube-map-vectors-transformed.png" /></a></p>
<p>If we compute R as before and use it to sample the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>, we get the wrong point in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. The viewer should see the point where R intersects the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, not the point where R intersects the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>. The correct point in the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> is picked out by the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> T. T is computed by transforming R by the inverse of the <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transformation. R was rotated by the <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transformation; the inverse <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transformation undoes that transformation, putting T into the same <abbr title="A way of assigning numerical coordinates to geometric points. In two dimensions, each point corresponds to a pair of numbers. In three dimensions, each point corresponds to a triple of numbers.">coordinate system</abbr> as the cube map. In this case, since R was rotated by 30 degrees, a <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr> of −30 degrees is applied to compute T. (This is just one way to understand the geometry. If you prefer to think of the cubemap as rotating along with the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>, then we need to apply a <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr> transformation to the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>—which is another way of saying that we need to transform R before using it to sample the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>.)</p>
<p>In the sample program, the <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> program that is used to represent the object is different from the one used to render the <abbr title="一个围绕场景的大立方体，用图像纹理，形成该场景所有方向的背景。">skybox</abbr>. The <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> is very typical. Note that the <abbr title="In OpenGL 1.1, a transform that combines the modeling transform with the viewing transform. That is, it is the composition of the transformation from object coordinates to world coordinates and the transformation from world coordinates to eye coordinates. Because of the equivalence between modeling and viewing transformations, world coordinates are not really meaningful for OpenGL, and only the combined transformation is tracked.">modelview transformation</abbr> can include modeling transforms that are applied to the object in addition to the <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transform that is applied to the entire scene. Here is the source code:</p>
<div class="highlight"><pre><span></span><code><span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">projection</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat4</span><span class="w"> </span><span class="nx">modelview</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">coords</span><span class="p">;</span>
<span class="nx">attribute</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">normal</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec4</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">modelview</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">vec4</span><span class="p">(</span><span class="nx">coords</span><span class="p">,</span><span class="mf">1.0</span><span class="p">);</span>
<span class="w">    </span><span class="nx">gl_Position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">projection</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_eyeCoords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">eyeCoords</span><span class="p">.</span><span class="nx">xyz</span><span class="p">;</span>
<span class="w">    </span><span class="nx">v_normal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normal</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>The <abbr title="One of the points that define a geometric primitive, such as the two endpoints of a line segment or the three vertices of a triangle. (The plural is &quot;vertices.&quot;) A vertex can be specified in a coordinate system by giving its x and y coordinates in 2D graphics, or its x, y, and z coordinates in 3D graphics.">vertex</abbr> <abbr title="A program to be executed at some stage of the rendering pipeline. OpenGL shaders are written in the GLSL programming languages. For WebGL, only vertex shaders and fragment shaders are supported. WebGPU also has compute shaders, which are used in compute pipelines.">shader</abbr> passes <abbr title="The coordinate system on 3D space defined by the viewer. In eye coordinates in OpenGL 1.1, the viewer is located at the origin, looking in the direction of the negative z-axis, with the positive y-axis pointing upwards, and the positive x-axis pointing to the right. The modelview transformation maps objects into the eye coordinate system, and the projection transform maps eye coordinates to clip coordinates.">eye coordinates</abbr> to the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> in a <abbr title="A variable that is used to communicate values from the vertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline. A varying variable is assigned a value in the vertex shader. The value of the variable in the fragment shader for a pixel in the primitive is obtained by interpolating the values from the vertices of the primitive. (In newer versions of GLSL, which support additional shader stages, the term &quot;varying variable&quot; is replaced by the more general terms &quot;in variable&quot; and &quot;out variable,&quot; which refer to variables that are used for input to or output from a shader.)">varying variable</abbr>. In <abbr title="The coordinate system on 3D space defined by the viewer. In eye coordinates in OpenGL 1.1, the viewer is located at the origin, looking in the direction of the negative z-axis, with the positive y-axis pointing upwards, and the positive x-axis pointing to the right. The modelview transformation maps objects into the eye coordinate system, and the projection transform maps eye coordinates to clip coordinates.">eye coordinates</abbr>, the viewer is at the point (0,0,0), and the <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr> V that points from the surface to the viewer is simply <em>−v_eyeCoords</em>.</p>
<p>The source code for the <abbr title="A shader program that will be executed once for each pixel in a primitive. A fragment shader must compute a color for the pixel, or discard it. Fragment shaders are also called pixel shaders.">fragment shader</abbr> implements the algorithm discussed above for <abbr title="The operation of mapping texture coordinates to colors from a texture, including using mipmaps if available and applying a minification or magnification filter if necessary.">sampling</abbr> the <abbr title="A texture made up of six images, one for each of the directions positive x, negative x, positive y, negative y, positive z, and negative z. The images are intended to include everything that can be seen from a given point. Cubemap textures are used for environment mapping and skyboxes.">cubemap texture</abbr>. Since we are doing perfect reflection, the color for the fragment comes directly from the <abbr title="Variation in some property from point-to-point on an object. The most common type is image texture. When an image texture is applied to a surface, the surface color varies from point to point.">texture</abbr>:</p>
<div class="highlight"><pre><span></span><code><span class="nx">precision</span><span class="w"> </span><span class="nx">mediump</span><span class="w"> </span><span class="kr">float</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">vCoords</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">;</span>
<span class="nx">varying</span><span class="w"> </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">samplerCube</span><span class="w"> </span><span class="nx">skybox</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat3</span><span class="w"> </span><span class="nx">normalMatrix</span><span class="p">;</span>
<span class="nx">uniform</span><span class="w"> </span><span class="nx">mat3</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="p">;</span>
<span class="ow">void</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">normalize</span><span class="p">(</span><span class="nx">normalMatrix</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">v_normal</span><span class="p">);</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="nx">v_eyeCoords</span><span class="p">;</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="nx">reflect</span><span class="p">(</span><span class="nx">V</span><span class="p">,</span><span class="nx">N</span><span class="p">);</span>
<span class="w">    </span><span class="nx">vec3</span><span class="w"> </span><span class="nx">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">inverseViewTransform</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">R</span><span class="p">;</span>
<span class="w">    </span><span class="nx">gl_FragColor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">textureCube</span><span class="p">(</span><span class="nx">skybox</span><span class="p">,</span><span class="w"> </span><span class="nx">T</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>The <em>inverseViewTransform</em> is computed on the <abbr title="A programming language for web pages. JavaScript code on a web page is executed by a web browser that displays the page, and it can interact with the contents of the web page and with the user. There are JavaScript APIs for 2D and for 3D graphics">JavaScript</abbr> side from the modelview <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>, after the <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transform has been applied but before any addition <abbr title="A transformation that is applied to an object to map that object into the world coordinate system or into the object coordinate system for a more complex, hierarchical object.">modeling transformation</abbr> is applied, using the commands</p>
<div class="highlight"><pre><span></span><code><span class="nx">mat3</span><span class="p">.</span><span class="nx">fromMat4</span><span class="p">(</span><span class="nx">inverseViewTransform</span><span class="p">,</span><span class="w"> </span><span class="nx">modelview</span><span class="p">);</span>
<span class="nx">mat3</span><span class="p">.</span><span class="nx">invert</span><span class="p">(</span><span class="nx">inverseViewTransform</span><span class="p">,</span><span class="nx">inverseViewTransform</span><span class="p">);</span>
</code></pre></div>
<p>We need a <strong><em>mat3</em></strong> to transform a <abbr title="An element of a vector space. Elements of a vector space can be added and can be multiplied by constants. For computer graphics, a vector is just a list or array containing two, three, or four numbers. Vectors in that sense are often used to represent points in 2D, 3D, or 4D space. Properly, however, a vector represents a quantity that has a length and a direction; a vector used in this way can be visualized as an arrow.">vector</abbr>. The first line discards the <abbr title="A geometric transform that adds a given translation amount to each coordinate of a point. Translation is used to move objects without changing their size or orientation.">translation</abbr> part of the modelview <abbr title="A rectangular array of numbers. A matrix can be represented as a two-dimensional array, with numbers arranged in rows and columns. An N-by-N matrix represents a linear transformation from N-dimensional space to itself.">matrix</abbr>, putting the result in <em>inverseViewTransform</em>. Translation doesn't affect vectors, but the <abbr title="A geometric transform that adds a given translation amount to each coordinate of a point. Translation is used to move objects without changing their size or orientation.">translation</abbr> part is zero in any case since the <abbr title="Setting the position and orientation of the viewer in a 3D world, which determine what will be visible when the 2D image of a 3D world is rendered.">viewing</abbr> transformation in this program is just a <abbr title="A geometric transform that rotates each point by a specified angle about some point (in 2D) or axis (in 3D).">rotation</abbr>. The second line converts <em>inverseViewTransform</em> into its inverse.</p>
</div>
</div>
</div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2024年6月19日</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2024年5月26日</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "content.tabs.link", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.top", "toc.follow", "content.tooltips"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>